[
  {
    "objectID": "environPy.html#coding-language",
    "href": "environPy.html#coding-language",
    "title": "Environment",
    "section": "Coding language",
    "text": "Coding language\nThis course is primarily designed to introduce Geographic Data Science using Python as the core programming language. All course materials, assignments, and exercises are built with Python in mind, ensuring consistency and clarity throughout the learning process. Python was selected for its versatility, extensive libraries, and widespread use in the Geographic Data Science field, making it an excellent choice for both beginners and advanced users. If you are curious about conducting similar geospatial analyses in R, you can access additional resources here. However, for this course, all work should be completed in Python and following the environment setup that we introduce below."
  },
  {
    "objectID": "environPy.html#reproducing-code-in-this-course",
    "href": "environPy.html#reproducing-code-in-this-course",
    "title": "Environment",
    "section": "Reproducing code in this course",
    "text": "Reproducing code in this course\nTo run the analysis and reproduce the code in Python, you will need to set up your Python environment according to the following instructions. Please follow the instructions according to your operating system.\n\n\n\n\n\n\nNote\n\n\n\nEven if you have used Python before and have set up your own environment, we very much recommend following the set up described below to ensure you can run the code smoothly.\n\n\nFollow these instructions and test your installation prior to the first session of the course. Setting up the Python environment is necessary for:\n\nExecuting the Jupyter notebooks of the sessions of the course.\nPreparing your own Jupyter notebooks.\n\nTo learn more about Jupyter notebooks, please visit this site."
  },
  {
    "objectID": "environPy.html#set-up-python",
    "href": "environPy.html#set-up-python",
    "title": "Environment",
    "section": "Set up Python",
    "text": "Set up Python\n\nInstallation of Miniconda\n\nInstall Miniconda on your personal laptop: Follow the instructions here.\nDuring the installation, leave the default settings. In particular, when asked whom to “Install Miniconda for”, choose “Just for me”.\n\n\n\nSet up the Directories\n\nCreate a folder where you want to keep your work conducted throughout this course. For example, call it gds4eco. You can save it wherever you want, but remember to be tidy with your folder structure!\nDownload the data to run and render the Jupyter notebooks. To learn how to download folders from github see the next section ?sec-download.\nUnzip the folders and store the nested folders into a subfolder named data within the folder gds4eco.\nCreate another subfolder named labs within gds4eco.\n\nThe folder structure should look like:\ngds4eco/\n├── data/\n└── labs/\n\n\nSet up the Python Environment\n\nMS WindowsMac\n\n\n\nDownload the gds4eco.yml from GitHub by cliciking Download raw file, top right at this page MODIFY!\nSave it in the folder gds4eco created before.\nType in the search bar and find the Anaconda Prompt (miniconda 3) in your personal computer. Launch it. The terminal should appear.\n\n\n\nIn the Anaconda Terminal write: conda env create -n gds4eco --file M:\\gds4eco\\gds4eco.yml and press Enter; if the file is located elsewhere you’ll need to use the corresponding file path.\nIf you are prompted any questions, press y. This process will install all the packages necessary to carry out the lab sessions.\nIn the Anaconda Terminal write conda activate gds4eco and press Enter. This activates your working environment.\n\n\n\n\nConfiguration of Jupyter Notebooks:\n\nIn the Anaconda Terminal, write jupyter server --generate-config and press enter. This, at least in Windows, should create a file to: C:\\Users\\username\\.jupyter\\jupyter_server_config.py.\nOpen the file with a text editor (e.g. Notepad++), do a ctrl-f search for: c.ServerApp.root_dir, uncomment it by removing the # and change it to c.ServerApp.notebook_dir = 'M:\\\\your\\\\new\\\\path, for example the directory where you created the gds4eco folder.\nSave the file and close it.\n\n\n\n\n\n\nDownload the gds4eco.yml from GitHub by clicking Download raw file, top right at this page.\nSave it in the folder envs363_563 created before.\nType in the search bar and open the Terminal.\nIn the Terminal write conda env create -n gds4eco --file gds4eco.yml and press Enter. This will need to be modified according to where you placed the gds4eco folder. For example, Elisabetta has named her folder gds4eco and it’s in her Dropbox in Users/PIETROST/Library/CloudStorage/Dropbox/envs363_563/envs363_563.yml. If you created the gds4eco folder on your desktop, the path would be Desktop/gds4eco.\n\n\n\nIf you are prompted any questions, press y. This process will install all the packages necessary to carry out the lab sessions.\nYou should then see this\n\n\n\n\n\n\n\nStart a Lab Session\n\nMS WindowsMac\n\n\n\nDownload the Jupyter Notebook of the session in your folder. Choose one Jupyter notebook and click Dowload raw file as shown below.\n\n\n\nSave the file in the labs folder within your geo4eco folder on your machine.\nType in the search bar, find and open the Anaconda Prompt (miniconda 3).\nIn the Anaconda Terminal write and run conda activate geo4eco.\nIn the Anaconda Terminal write and run jupyter notebook. This should open Jupyter Notebook in your default browser.\n\n\n\nNavigate to your course folder in and double click on the notebook downloaded in step 1.\nYou can now work on your copy of the notebook.\n\n\n\n\nDownload the Jupyter Notebook of the session in your folder. Choose one jupyter notebook and click Dowload raw file as shown below\n\n\n\nSave the file in the labs folder within your envs363 folder on your machine.\nType in the search bar, find and open the Terminal.\nIn the Terminal write and run conda activate envs363.\nIn the Terminal write and run jupyter notebook.\n\n\n\nThis should open Jupyter Notebook in your default browser. You should see something like this:\n\n\n\nNavigate to your folder. You can now work on your copy of the notebook."
  },
  {
    "objectID": "environPy.html#py-basics",
    "href": "environPy.html#py-basics",
    "title": "Environment",
    "section": "Py Basics",
    "text": "Py Basics\nPlease refer to the tutorials from learnpython.org for an introduction to coding in Python. We particularly recommend the tutorials listed under the “Learn the Basics” section."
  },
  {
    "objectID": "environPy.html#resources",
    "href": "environPy.html#resources",
    "title": "Environment",
    "section": "Resources",
    "text": "Resources\nSome help along the way with:\n\nGeographic Data Science with Python.\nPython for Geographic Data Analysis"
  },
  {
    "objectID": "spatial-data.html#data-tables",
    "href": "spatial-data.html#data-tables",
    "title": "1  Spatial data",
    "section": "",
    "text": "1.1.1 Points\nAssuming you have the file locally on the path ./data/:\n\npts = geopandas.read_file(\"./data/madrid_abb.gpkg\")\n\n\n\n\n\n\n\nNote\n\n\n\nSometimes, points are provided as separate columns in an otherwise non-spatial table. For example imagine we have an object cols with a column named X for longitude and Y for latitude. Then, we can convert those into proper geometries by running pts = geopandas.GeoSeries( geopandas.points_from_xy(cols[\"X\"], cols[\"Y\"]).\n\n\nLet’s explore the points dataset that we loaded above.\n\npts.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 18399 entries, 0 to 18398\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype   \n---  ------           --------------  -----   \n 0   price            18399 non-null  object  \n 1   price_usd        18399 non-null  float64 \n 2   log1p_price_usd  18399 non-null  float64 \n 3   accommodates     18399 non-null  int64   \n 4   bathrooms        18399 non-null  object  \n 5   bedrooms         18399 non-null  float64 \n 6   beds             18399 non-null  float64 \n 7   neighbourhood    18399 non-null  object  \n 8   room_type        18399 non-null  object  \n 9   property_type    18399 non-null  object  \n 10  WiFi             18399 non-null  object  \n 11  Coffee           18399 non-null  object  \n 12  Gym              18399 non-null  object  \n 13  Parking          18399 non-null  object  \n 14  km_to_retiro     18399 non-null  float64 \n 15  geometry         18399 non-null  geometry\ndtypes: float64(5), geometry(1), int64(1), object(9)\nmemory usage: 2.2+ MB\n\n\n\npts.head()\n\n\n\n\n\n\n\n\nprice\nprice_usd\nlog1p_price_usd\naccommodates\nbathrooms\nbedrooms\nbeds\nneighbourhood\nroom_type\nproperty_type\nWiFi\nCoffee\nGym\nParking\nkm_to_retiro\ngeometry\n\n\n\n\n0\n$60.00\n60.0\n4.110874\n2\n1 shared bath\n1.0\n1.0\nHispanoamérica\nPrivate room\nPrivate room in apartment\n1\n0\n0\n0\n5.116664\nPOINT (-3.67688 40.45724)\n\n\n1\n$31.00\n31.0\n3.465736\n1\n1 bath\n1.0\n1.0\nCármenes\nPrivate room\nPrivate room in apartment\n1\n1\n0\n1\n5.563869\nPOINT (-3.74084 40.40341)\n\n\n2\n$60.00\n60.0\n4.110874\n6\n2 baths\n3.0\n5.0\nLegazpi\nEntire home/apt\nEntire apartment\n1\n1\n0\n1\n3.048442\nPOINT (-3.69304 40.38695)\n\n\n3\n$115.00\n115.0\n4.753590\n4\n1.5 baths\n2.0\n3.0\nJusticia\nEntire home/apt\nEntire apartment\n1\n1\n0\n1\n2.075484\nPOINT (-3.69764 40.41995)\n\n\n4\n$26.00\n26.0\n3.295837\n1\n1 private bath\n1.0\n1.0\nLegazpi\nPrivate room\nPrivate room in house\n1\n0\n0\n0\n2.648058\nPOINT (-3.69011 40.38985)\n\n\n\n\n\n\n\n\n\n1.1.2 Lines\nAssuming you have the file locally on the path ./data/:\n\nlines = geopandas.read_file(\"./data/arturo_streets.gpkg\")\n\n\nlines.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 66499 entries, 0 to 66498\nData columns (total 9 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   OGC_FID             66499 non-null  object  \n 1   dm_id               66499 non-null  object  \n 2   dist_barri          66483 non-null  object  \n 3   average_quality     66499 non-null  float64 \n 4   population_density  66499 non-null  float64 \n 5   X                   66499 non-null  float64 \n 6   Y                   66499 non-null  float64 \n 7   value               5465 non-null   float64 \n 8   geometry            66499 non-null  geometry\ndtypes: float64(5), geometry(1), object(3)\nmemory usage: 4.6+ MB\n\n\n\nlines.loc[0, \"geometry\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Print descriptive statistics for population_density and average_quality.\n\n\n\n\n1.1.3 Polygons\nAssuming you have the file locally on the path ./data/:\n\npolys = geopandas.read_file(\"./data/neighbourhoods.geojson\")\n\n\npolys.head()\n\n\n\n\n\n\n\n\nneighbourhood\nneighbourhood_group\ngeometry\n\n\n\n\n0\nPalacio\nCentro\nMULTIPOLYGON (((-3.70584 40.42030, -3.70625 40...\n\n\n1\nEmbajadores\nCentro\nMULTIPOLYGON (((-3.70384 40.41432, -3.70277 40...\n\n\n2\nCortes\nCentro\nMULTIPOLYGON (((-3.69796 40.41929, -3.69645 40...\n\n\n3\nJusticia\nCentro\nMULTIPOLYGON (((-3.69546 40.41898, -3.69645 40...\n\n\n4\nUniversidad\nCentro\nMULTIPOLYGON (((-3.70107 40.42134, -3.70155 40...\n\n\n\n\n\n\n\n\npolys.query(\"neighbourhood_group == 'Retiro'\")\n\n\n\n\n\n\n\n\nneighbourhood\nneighbourhood_group\ngeometry\n\n\n\n\n13\nPacífico\nRetiro\nMULTIPOLYGON (((-3.67015 40.40654, -3.67017 40...\n\n\n14\nAdelfas\nRetiro\nMULTIPOLYGON (((-3.67283 40.39468, -3.67343 40...\n\n\n15\nEstrella\nRetiro\nMULTIPOLYGON (((-3.66506 40.40647, -3.66512 40...\n\n\n16\nIbiza\nRetiro\nMULTIPOLYGON (((-3.66916 40.41796, -3.66927 40...\n\n\n17\nJerónimos\nRetiro\nMULTIPOLYGON (((-3.67874 40.40751, -3.67992 40...\n\n\n18\nNiño Jesús\nRetiro\nMULTIPOLYGON (((-3.66994 40.40850, -3.67012 40...\n\n\n\n\n\n\n\n\npolys.neighbourhood_group.unique()\n\narray(['Centro', 'Arganzuela', 'Retiro', 'Salamanca', 'Chamartín',\n       'Moratalaz', 'Tetuán', 'Chamberí', 'Fuencarral - El Pardo',\n       'Moncloa - Aravaca', 'Puente de Vallecas', 'Latina', 'Carabanchel',\n       'Usera', 'Ciudad Lineal', 'Hortaleza', 'Villaverde',\n       'Villa de Vallecas', 'Vicálvaro', 'San Blas - Canillejas',\n       'Barajas'], dtype=object)",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial-data.html#surfaces",
    "href": "spatial-data.html#surfaces",
    "title": "1  Spatial data",
    "section": "1.3 Surfaces",
    "text": "1.3 Surfaces\nAssuming you have the file locally on the path ./data/:\n\nsat = rioxarray.open_rasterio(\"./data/madrid_scene_s2_10_tc.tif\")\n\n\nsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 3, y: 3681, x: 3129)&gt;\n[34553547 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3\n  * x            (x) float64 4.248e+05 4.248e+05 4.248e+05 ... 4.56e+05 4.56e+05\n  * y            (y) float64 4.499e+06 4.499e+06 ... 4.463e+06 4.463e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 3y: 3681x: 3129...[34553547 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3array([1, 2, 3])x(x)float644.248e+05 4.248e+05 ... 4.56e+05array([424765., 424775., 424785., ..., 456025., 456035., 456045.])y(y)float644.499e+06 4.499e+06 ... 4.463e+06array([4499365., 4499355., 4499345., ..., 4462585., 4462575., 4462565.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 30Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-3.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]GeoTransform :424760.0 10.0 0.0 4499370.0 0.0 -10.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Int64Index([1, 2, 3], dtype='int64', name='band'))xPandasIndexPandasIndex(Float64Index([424765.0, 424775.0, 424785.0, 424795.0, 424805.0, 424815.0,\n              424825.0, 424835.0, 424845.0, 424855.0,\n              ...\n              455955.0, 455965.0, 455975.0, 455985.0, 455995.0, 456005.0,\n              456015.0, 456025.0, 456035.0, 456045.0],\n             dtype='float64', name='x', length=3129))yPandasIndexPandasIndex(Float64Index([4499365.0, 4499355.0, 4499345.0, 4499335.0, 4499325.0, 4499315.0,\n              4499305.0, 4499295.0, 4499285.0, 4499275.0,\n              ...\n              4462655.0, 4462645.0, 4462635.0, 4462625.0, 4462615.0, 4462605.0,\n              4462595.0, 4462585.0, 4462575.0, 4462565.0],\n             dtype='float64', name='y', length=3681))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\n\nsat.sel(band=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 3681, x: 3129)&gt;\n[11517849 values with dtype=uint8]\nCoordinates:\n    band         int64 1\n  * x            (x) float64 4.248e+05 4.248e+05 4.248e+05 ... 4.56e+05 4.56e+05\n  * y            (y) float64 4.499e+06 4.499e+06 ... 4.463e+06 4.463e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayy: 3681x: 3129...[11517849 values with dtype=uint8]Coordinates: (4)band()int641array(1)x(x)float644.248e+05 4.248e+05 ... 4.56e+05array([424765., 424775., 424785., ..., 456025., 456035., 456045.])y(y)float644.499e+06 4.499e+06 ... 4.463e+06array([4499365., 4499355., 4499345., ..., 4462585., 4462575., 4462565.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 30Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-3.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]GeoTransform :424760.0 10.0 0.0 4499370.0 0.0 -10.0array(0)Indexes: (2)xPandasIndexPandasIndex(Float64Index([424765.0, 424775.0, 424785.0, 424795.0, 424805.0, 424815.0,\n              424825.0, 424835.0, 424845.0, 424855.0,\n              ...\n              455955.0, 455965.0, 455975.0, 455985.0, 455995.0, 456005.0,\n              456015.0, 456025.0, 456035.0, 456045.0],\n             dtype='float64', name='x', length=3129))yPandasIndexPandasIndex(Float64Index([4499365.0, 4499355.0, 4499345.0, 4499335.0, 4499325.0, 4499315.0,\n              4499305.0, 4499295.0, 4499285.0, 4499275.0,\n              ...\n              4462655.0, 4462645.0, 4462635.0, 4462625.0, 4462615.0, 4462605.0,\n              4462595.0, 4462585.0, 4462575.0, 4462565.0],\n             dtype='float64', name='y', length=3681))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\n\nsat.sel(\n    x=slice(430000, 440000),  # x is ascending\n    y=slice(4480000, 4470000) # y is descending\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 3, y: 1000, x: 1000)&gt;\n[3000000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3\n  * x            (x) float64 4.3e+05 4.3e+05 4.3e+05 ... 4.4e+05 4.4e+05 4.4e+05\n  * y            (y) float64 4.48e+06 4.48e+06 4.48e+06 ... 4.47e+06 4.47e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 3y: 1000x: 1000...[3000000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3array([1, 2, 3])x(x)float644.3e+05 4.3e+05 ... 4.4e+05 4.4e+05array([430005., 430015., 430025., ..., 439975., 439985., 439995.])y(y)float644.48e+06 4.48e+06 ... 4.47e+06array([4479995., 4479985., 4479975., ..., 4470025., 4470015., 4470005.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 30Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-3.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]GeoTransform :424760.0 10.0 0.0 4499370.0 0.0 -10.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Int64Index([1, 2, 3], dtype='int64', name='band'))xPandasIndexPandasIndex(Float64Index([430005.0, 430015.0, 430025.0, 430035.0, 430045.0, 430055.0,\n              430065.0, 430075.0, 430085.0, 430095.0,\n              ...\n              439905.0, 439915.0, 439925.0, 439935.0, 439945.0, 439955.0,\n              439965.0, 439975.0, 439985.0, 439995.0],\n             dtype='float64', name='x', length=1000))yPandasIndexPandasIndex(Float64Index([4479995.0, 4479985.0, 4479975.0, 4479965.0, 4479955.0, 4479945.0,\n              4479935.0, 4479925.0, 4479915.0, 4479905.0,\n              ...\n              4470095.0, 4470085.0, 4470075.0, 4470065.0, 4470055.0, 4470045.0,\n              4470035.0, 4470025.0, 4470015.0, 4470005.0],\n             dtype='float64', name='y', length=1000))Attributes: (3)AREA_OR_POINT :Areascale_factor :1.0add_offset :0.0\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Subset sat to band 2 and the section within [444444, 455555] of Easting and [4470000, 4480000] of Northing.\n\nHow many pixels does it contain?\nWhat if you used bands 1 and 3 instead?",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial-data.html#visualisation",
    "href": "spatial-data.html#visualisation",
    "title": "1  Spatial data",
    "section": "1.4 Visualisation",
    "text": "1.4 Visualisation\nYou will need version 0.10.0 or greater of geopandas to use explore.\n\npolys.explore()\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfig, ax = plt.subplots()\npolys.plot(ax=ax)\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nlines.plot(linewidth=0.1, color=\"black\", ax=ax)\n#contextily.add_basemap(ax, crs=lines.crs)\nplt.show()\n\n\n\n\n\n\n\n\nSee more basemap options here.\n\nfig, ax = plt.subplots()\npts.plot(color=\"red\", figsize=(12, 12), markersize=0.1, ax=ax)\ncontextily.add_basemap(\n    ax,\n    crs = pts.crs,\n    source = contextily.providers.CartoDB.DarkMatter\n)\nplt.show()\n\n\n\n\n\n\n\n\n\nsat.plot.imshow(figsize=(12, 12))\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 10))\nsat.plot.imshow(ax=ax)\ncontextily.add_basemap(\n    ax,\n    crs=sat.rio.crs,\n    source=contextily.providers.CartoDB.VoyagerOnlyLabels,\n    zoom=11,\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Make three plots of sat, plotting one single band in each.",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial-data.html#spatial-operations",
    "href": "spatial-data.html#spatial-operations",
    "title": "1  Spatial data",
    "section": "1.5 Spatial operations",
    "text": "1.5 Spatial operations\n\n1.5.1 (Re-)Projections\n\npts.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsat.rio.crs\n\nCRS.from_epsg(32630)\n\n\n\npts.to_crs(sat.rio.crs).crs\n\n&lt;Projected CRS: EPSG:32630&gt;\nName: WGS 84 / UTM zone 30N\nAxis Info [cartesian]:\n- [east]: Easting (metre)\n- [north]: Northing (metre)\nArea of Use:\n- undefined\nCoordinate Operation:\n- name: UTM zone 30N\n- method: Transverse Mercator\nDatum: World Geodetic System 1984\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsat.rio.reproject(pts.crs).rio.crs\n\nCRS.from_epsg(4326)\n\n\n\n# All into Web Mercator (EPSG:3857)\nfig, ax = plt.subplots(1, figsize=(12, 12))\n\n## Satellite image\nsat.rio.reproject(\n    \"EPSG:3857\"\n).plot.imshow(\n    ax=ax\n)\n\n## Neighbourhoods\npolys.to_crs(epsg=3857).plot(\n    linewidth=1, \n    edgecolor=\"xkcd:lime\", \n    facecolor=\"none\",\n    ax=ax\n)\n\n## Labels\ncontextily.add_basemap( # No need to reproject\n    ax,\n    source=contextily.providers.CartoDB.VoyagerOnlyLabels,\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n1.5.2 Centroids\nNote the warning that geometric operations with non-projected CRS object result in biases.\n\npolys.centroid\n\n/var/folders/79/65l52xsj7vq_4_t_l6k5bl2c0000gn/T/ipykernel_25797/2101097851.py:1: UserWarning:\n\nGeometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n\n\n\n0      POINT (-3.71398 40.41543)\n1      POINT (-3.70237 40.40925)\n2      POINT (-3.69674 40.41485)\n3      POINT (-3.69657 40.42367)\n4      POINT (-3.70698 40.42568)\n                 ...            \n123    POINT (-3.59135 40.45656)\n124    POINT (-3.59723 40.48441)\n125    POINT (-3.55847 40.47613)\n126    POINT (-3.57889 40.47471)\n127    POINT (-3.60718 40.46415)\nLength: 128, dtype: geometry\n\n\nIt is therefore important to re-project these geometries to a projected crs such as we did with with pts before.\n\npolys = polys.to_crs(sat.rio.crs)\n\nNow, we can compute centroids without warnings:\n\npolys.centroid\n\n0      POINT (439425.451 4474112.019)\n1      POINT (440404.977 4473418.085)\n2      POINT (440887.707 4474036.547)\n3      POINT (440909.920 4475014.820)\n4      POINT (440028.666 4475245.024)\n                    ...              \n123    POINT (449860.280 4478601.086)\n124    POINT (449382.527 4481695.863)\n125    POINT (452661.832 4480754.248)\n126    POINT (450929.735 4480608.573)\n127    POINT (448523.423 4479452.348)\nLength: 128, dtype: geometry\n\n\n\nfig, ax = plt.subplots()\npolys.plot(color=\"purple\", ax=ax)\npolys.centroid.plot(\n    ax=ax, color=\"lime\", markersize=1\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n1.5.3 Spatial joins\nMore information about spatial joins in geopandas is available on its documentation page.\nLet’s ensure that the geometries we are looking to join are in the same projection.\n\nlines = lines.to_crs(polys.crs)\n\n\nsj = geopandas.sjoin(\n    lines,\n    polys\n)\n\n\nsj.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nInt64Index: 69420 entries, 0 to 66438\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype   \n---  ------               --------------  -----   \n 0   OGC_FID              69420 non-null  object  \n 1   dm_id                69420 non-null  object  \n 2   dist_barri           69414 non-null  object  \n 3   average_quality      69420 non-null  float64 \n 4   population_density   69420 non-null  float64 \n 5   X                    69420 non-null  float64 \n 6   Y                    69420 non-null  float64 \n 7   value                5769 non-null   float64 \n 8   geometry             69420 non-null  geometry\n 9   index_right          69420 non-null  int64   \n 10  neighbourhood        69420 non-null  object  \n 11  neighbourhood_group  69420 non-null  object  \ndtypes: float64(5), geometry(1), int64(1), object(5)\nmemory usage: 6.9+ MB\n\n\n\nfig, ax = plt.subplots()\n\n# Subset of lines\nsj.query(\n    \"neighbourhood == 'Jerónimos'\"\n).plot(color=\"xkcd:bright turquoise\", ax=ax)\n\n# Subset of line centroids\nsj.query(\n    \"neighbourhood == 'Jerónimos'\"\n).centroid.plot(\n    color=\"xkcd:bright violet\", markersize=7, ax=ax\n)\n\n# Local basemap\ncontextily.add_basemap(\n    ax,\n    crs=sj.crs,\n    source=\"./data/madrid_scene_s2_10_tc.tif\",\n    alpha=0.5\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsj.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nInt64Index: 69420 entries, 0 to 66438\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype   \n---  ------               --------------  -----   \n 0   OGC_FID              69420 non-null  object  \n 1   dm_id                69420 non-null  object  \n 2   dist_barri           69414 non-null  object  \n 3   average_quality      69420 non-null  float64 \n 4   population_density   69420 non-null  float64 \n 5   X                    69420 non-null  float64 \n 6   Y                    69420 non-null  float64 \n 7   value                5769 non-null   float64 \n 8   geometry             69420 non-null  geometry\n 9   index_right          69420 non-null  int64   \n 10  neighbourhood        69420 non-null  object  \n 11  neighbourhood_group  69420 non-null  object  \ndtypes: float64(5), geometry(1), int64(1), object(5)\nmemory usage: 6.9+ MB\n\n\n\n\n1.5.4 Areas\nTo compute areas of polygons, use a projected crs (we already transformed polys to the same projection as sat, which is a projected crs).\n\nareas = polys.area * 1e-6 # Km2\nareas.head()\n\n0    1.471037\n1    1.033253\n2    0.592049\n3    0.742031\n4    0.947616\ndtype: float64\n\n\n\n\n1.5.5 Distances\nWe can give geopandas.tools.geocode() a string or a set of strings corresponding to addresses. It will geocode it and return a GeoDataFrame of the resulting point geometries\n\ncemfi = geopandas.tools.geocode(\n    \"Calle Casado del Alisal, 5, Madrid\"\n).to_crs(sat.rio.crs)\n\n\ncemfi\n\n\n\n\n\n\n\n\ngeometry\naddress\n\n\n\n\n0\nPOINT (441477.245 4473939.537)\n5, Calle Casado del Alisal, 28014, Calle Casad...\n\n\n\n\n\n\n\nWe can compute the distance between the point for cemfi and the centroids of all the polygons in polys ensuring they both are in the same crs:\n\npolys.to_crs(\n    cemfi.crs\n).distance(\n    cemfi.geometry\n)\n\n/var/folders/79/65l52xsj7vq_4_t_l6k5bl2c0000gn/T/ipykernel_25797/176561454.py:3: UserWarning:\n\nThe indices of the two GeoSeries are different.\n\n\n\n0      1491.338749\n1              NaN\n2              NaN\n3              NaN\n4              NaN\n          ...     \n123            NaN\n124            NaN\n125            NaN\n126            NaN\n127            NaN\nLength: 128, dtype: float64\n\n\n\nd2cemfi = polys.to_crs(\n    cemfi.crs\n).distance(\n    cemfi.geometry[0] # NO index\n)\nd2cemfi.head()\n\n0    1491.338749\n1     565.418135\n2     278.121017\n3     650.926572\n4    1196.771601\ndtype: float64\n\n\nMake a map, colouring the polygons according the the distance of their centroid to cemfi:\n\nfig, ax = plt.subplots()\n\npolys.assign(\n    dist=d2cemfi/1000\n).plot(\"dist\", legend=True, ax=ax)\n\ncemfi.to_crs(\n    polys.crs\n).plot(\n    marker=\"*\", \n    markersize=15, \n    color=\"r\", \n    label=\"CEMFI\", \n    ax=ax\n)\n\nax.legend()\nax.set_title(\n    \"Distance to CEMFI\"\n)\n\nplt.show()",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial-data.html#next-steps",
    "href": "spatial-data.html#next-steps",
    "title": "1  Spatial data",
    "section": "1.6 Next steps",
    "text": "1.6 Next steps\nIf you are interested in following up on some of the topics explored in this block, the following pointers might be useful:\n\nAlthough we have seen here geopandas only, all non-geographic operations on geo-tables are really thanks to pandas, the workhorse for tabular data in Python. Their official documentation is an excellent first stop. If you prefer a book, (McKinney 2013) is a great one.\nFor more detail on geographic operations on geo-tables, the Geopandas official documentation is a great place to continue the journey.\nSurfaces, as covered here, are really an example of multi-dimensional labelled arrays. The library we use, xarray represents the cutting edge for working with these data structures in Python, and their documentation is a great place to wrap your head around how data of this type can be manipulated. For geographic extensions (CRS handling, reprojections, etc.), we have used rioxarray under the hood, and its documentation is also well worth checking.\n\n\n\n\n\nMcKinney, Wes. 2013. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. 1st ed. Paperback; O’Reilly Media. http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\\&path=ASIN/1449319793.\n\n\nPietrostefani, Elisabetta, and Carmen Cabrera-Arnau. 2024. “A Course in Geographic Data Science.” https://pietrostefani.github.io/gds/.\n\n\nRey, Sergio J., Daniel Arribas-Bel, and Levi J. Wolf. forthcoming. Geographic Data Science with PySAL and the PyData Stack. CRC press.",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "geovisualisation.html#importing-modules",
    "href": "geovisualisation.html#importing-modules",
    "title": "Geovisualisation",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "geovisualisation.html#datasets",
    "href": "geovisualisation.html#datasets",
    "title": "Geovisualisation",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "geovisualisation.html#inspecting-spatial-data",
    "href": "geovisualisation.html#inspecting-spatial-data",
    "title": "Geovisualisation",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "geovisualisation.html#styling-plots",
    "href": "geovisualisation.html#styling-plots",
    "title": "Geovisualisation",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "geovisualisation.html#coordinate-reference-systems",
    "href": "geovisualisation.html#coordinate-reference-systems",
    "title": "Geovisualisation",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "geovisualisation.html#manipulating-spatial-tables",
    "href": "geovisualisation.html#manipulating-spatial-tables",
    "title": "Geovisualisation",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "geovisualisation.html#joins",
    "href": "geovisualisation.html#joins",
    "title": "Geovisualisation",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "geovisualisation.html#join-districts-with-educational-level-data",
    "href": "geovisualisation.html#join-districts-with-educational-level-data",
    "title": "Geovisualisation",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "geovisualisation.html#saving-maps-to-figures",
    "href": "geovisualisation.html#saving-maps-to-figures",
    "title": "Geovisualisation",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "geovisualisation.html#adding-baselayers",
    "href": "geovisualisation.html#adding-baselayers",
    "title": "Geovisualisation",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "geovisualisation.html#interactive-maps",
    "href": "geovisualisation.html#interactive-maps",
    "title": "Geovisualisation",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "spatial-feature-i.html#importing-modules",
    "href": "spatial-feature-i.html#importing-modules",
    "title": "Spatial feature engineering (I)",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "spatial-feature-i.html#datasets",
    "href": "spatial-feature-i.html#datasets",
    "title": "Spatial feature engineering (I)",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "spatial-feature-i.html#inspecting-spatial-data",
    "href": "spatial-feature-i.html#inspecting-spatial-data",
    "title": "Spatial feature engineering (I)",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "spatial-feature-i.html#styling-plots",
    "href": "spatial-feature-i.html#styling-plots",
    "title": "Spatial feature engineering (I)",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "spatial-feature-i.html#coordinate-reference-systems",
    "href": "spatial-feature-i.html#coordinate-reference-systems",
    "title": "Spatial feature engineering (I)",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-i.html#manipulating-spatial-tables",
    "href": "spatial-feature-i.html#manipulating-spatial-tables",
    "title": "Spatial feature engineering (I)",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-i.html#joins",
    "href": "spatial-feature-i.html#joins",
    "title": "Spatial feature engineering (I)",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "spatial-feature-i.html#join-districts-with-educational-level-data",
    "href": "spatial-feature-i.html#join-districts-with-educational-level-data",
    "title": "Spatial feature engineering (I)",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "spatial-feature-i.html#saving-maps-to-figures",
    "href": "spatial-feature-i.html#saving-maps-to-figures",
    "title": "Spatial feature engineering (I)",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "spatial-feature-i.html#adding-baselayers",
    "href": "spatial-feature-i.html#adding-baselayers",
    "title": "Spatial feature engineering (I)",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-i.html#interactive-maps",
    "href": "spatial-feature-i.html#interactive-maps",
    "title": "Spatial feature engineering (I)",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "spatial-feature-ii.html#importing-modules",
    "href": "spatial-feature-ii.html#importing-modules",
    "title": "Spatial feature engineering (II)",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "spatial-feature-ii.html#datasets",
    "href": "spatial-feature-ii.html#datasets",
    "title": "Spatial feature engineering (II)",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "spatial-feature-ii.html#inspecting-spatial-data",
    "href": "spatial-feature-ii.html#inspecting-spatial-data",
    "title": "Spatial feature engineering (II)",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "spatial-feature-ii.html#styling-plots",
    "href": "spatial-feature-ii.html#styling-plots",
    "title": "Spatial feature engineering (II)",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "spatial-feature-ii.html#coordinate-reference-systems",
    "href": "spatial-feature-ii.html#coordinate-reference-systems",
    "title": "Spatial feature engineering (II)",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-ii.html#manipulating-spatial-tables",
    "href": "spatial-feature-ii.html#manipulating-spatial-tables",
    "title": "Spatial feature engineering (II)",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-ii.html#joins",
    "href": "spatial-feature-ii.html#joins",
    "title": "Spatial feature engineering (II)",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "spatial-feature-ii.html#join-districts-with-educational-level-data",
    "href": "spatial-feature-ii.html#join-districts-with-educational-level-data",
    "title": "Spatial feature engineering (II)",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "spatial-feature-ii.html#saving-maps-to-figures",
    "href": "spatial-feature-ii.html#saving-maps-to-figures",
    "title": "Spatial feature engineering (II)",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "spatial-feature-ii.html#adding-baselayers",
    "href": "spatial-feature-ii.html#adding-baselayers",
    "title": "Spatial feature engineering (II)",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "spatial-feature-ii.html#interactive-maps",
    "href": "spatial-feature-ii.html#interactive-maps",
    "title": "Spatial feature engineering (II)",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "openstreetmap.html#importing-modules",
    "href": "openstreetmap.html#importing-modules",
    "title": "OpenStreetMap",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "openstreetmap.html#datasets",
    "href": "openstreetmap.html#datasets",
    "title": "OpenStreetMap",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "openstreetmap.html#inspecting-spatial-data",
    "href": "openstreetmap.html#inspecting-spatial-data",
    "title": "OpenStreetMap",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "openstreetmap.html#styling-plots",
    "href": "openstreetmap.html#styling-plots",
    "title": "OpenStreetMap",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "openstreetmap.html#coordinate-reference-systems",
    "href": "openstreetmap.html#coordinate-reference-systems",
    "title": "OpenStreetMap",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "openstreetmap.html#manipulating-spatial-tables",
    "href": "openstreetmap.html#manipulating-spatial-tables",
    "title": "OpenStreetMap",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "openstreetmap.html#joins",
    "href": "openstreetmap.html#joins",
    "title": "OpenStreetMap",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "openstreetmap.html#join-districts-with-educational-level-data",
    "href": "openstreetmap.html#join-districts-with-educational-level-data",
    "title": "OpenStreetMap",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "openstreetmap.html#saving-maps-to-figures",
    "href": "openstreetmap.html#saving-maps-to-figures",
    "title": "OpenStreetMap",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "openstreetmap.html#adding-baselayers",
    "href": "openstreetmap.html#adding-baselayers",
    "title": "OpenStreetMap",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "openstreetmap.html#interactive-maps",
    "href": "openstreetmap.html#interactive-maps",
    "title": "OpenStreetMap",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "transport-costs.html#importing-modules",
    "href": "transport-costs.html#importing-modules",
    "title": "Transport costs",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "transport-costs.html#datasets",
    "href": "transport-costs.html#datasets",
    "title": "Transport costs",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "transport-costs.html#inspecting-spatial-data",
    "href": "transport-costs.html#inspecting-spatial-data",
    "title": "Transport costs",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "transport-costs.html#styling-plots",
    "href": "transport-costs.html#styling-plots",
    "title": "Transport costs",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "transport-costs.html#coordinate-reference-systems",
    "href": "transport-costs.html#coordinate-reference-systems",
    "title": "Transport costs",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "transport-costs.html#manipulating-spatial-tables",
    "href": "transport-costs.html#manipulating-spatial-tables",
    "title": "Transport costs",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "transport-costs.html#joins",
    "href": "transport-costs.html#joins",
    "title": "Transport costs",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "transport-costs.html#join-districts-with-educational-level-data",
    "href": "transport-costs.html#join-districts-with-educational-level-data",
    "title": "Transport costs",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "transport-costs.html#saving-maps-to-figures",
    "href": "transport-costs.html#saving-maps-to-figures",
    "title": "Transport costs",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "transport-costs.html#adding-baselayers",
    "href": "transport-costs.html#adding-baselayers",
    "title": "Transport costs",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "transport-costs.html#interactive-maps",
    "href": "transport-costs.html#interactive-maps",
    "title": "Transport costs",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "web-mapping.html#importing-modules",
    "href": "web-mapping.html#importing-modules",
    "title": "Web mapping with CARTO",
    "section": "Importing modules",
    "text": "Importing modules\n\n# Import the pandas library, which is useful for data manipulation and analysis.\nimport pandas as pd\n# Import the geopandas library, which extends pandas to support spatial data operations.\nimport geopandas as gpd\n# Import the Point class from the shapely.geometry module, used for handling geometric points.\nfrom shapely.geometry import Point\n# Import the osmnx library, which simplifies the process of downloading and analyzing street networks and other geospatial data from OpenStreetMap.\nimport osmnx as ox\n# Import the contextily library, which is used for adding basemaps (like raster tiles) to geospatial plots.\nimport contextily as cx\n# Import the pyplot module from matplotlib, a library for creating static, animated, and interactive visualizations in Python.\nimport matplotlib.pyplot as plt\n# Import the CRS class from pyproj, which provides tools for defining and transforming coordinate reference systems.\nfrom pyproj import CRS\n# Operating systems\nimport os\n# Interactive maps\nimport folium\n# Import the display function\nfrom IPython.display import display"
  },
  {
    "objectID": "web-mapping.html#datasets",
    "href": "web-mapping.html#datasets",
    "title": "Web mapping with CARTO",
    "section": "Datasets",
    "text": "Datasets\nToday we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.\n\nCreating geographic data\nFirst we will use the following commands create geographic datasets from scratch representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\n# Create the DataFrame\ndata = {\n    'name': [\"The British Museum\", \"Big Ben\", \"King's Cross\", \"The Natural History Museum\"],\n    'lon': [-0.1459604, -0.1272057, -0.1319481, -0.173734],\n    'lat': [51.5045975, 51.5007325, 51.5301701, 51.4938451]\n}\npoi_df = pd.DataFrame(data)\n\n# Convert DataFrame to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(poi_df['lon'], poi_df['lat'])]\npoi_gdf = gpd.GeoDataFrame(poi_df, geometry=geometry)\n\n# Set the coordinate reference system (CRS)\npoi_gdf.set_crs(epsg=4326, inplace=True)\n\nprint(poi_gdf)\n\n                         name       lon        lat                   geometry\n0          The British Museum -0.145960  51.504598  POINT (-0.14596 51.50460)\n1                     Big Ben -0.127206  51.500732  POINT (-0.12721 51.50073)\n2                King's Cross -0.131948  51.530170  POINT (-0.13195 51.53017)\n3  The Natural History Museum -0.173734  51.493845  POINT (-0.17373 51.49385)\n\n\n\n\nTypes of Data\nNow let’s look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.\n\nPolygonsLinesPoints\n\n\nWe first import the district shapefile use gpd.read_file, we then plot it to make sure we are seeing it ‘correctly’.\n\n# Read the shapefile for districts\ndistricts = gpd.read_file(\"data/London/Polygons/districts.shp\")\n\n# Create a simple plot\ndistricts.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe them import a file of roads in London and plot it.\n\n# Read the shapefile for A roads\na_roads = gpd.read_file(\"data/London/Lines/a_roads.shp\")\n\n# If you needed to import a `geojson` file, this would be the function:\n# a_roads = gpd.read_file(\"data/London/Lines/a_roads.geojson\")\n\n# Create a simple plot of the roads\na_roads.plot()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nWe can also import point files. So far, we have imported shapefiles and geojsons, but we can also obtain data from urls like in the Open Science DIY session or from other sources like OpenStreetMap. Both R and Python have libraries that allow us to query OpenStreetMap.\nNote that we use the method features_from_place, which queries for points in a particular place (London in this case) and creates a GeoDataFrame of OSM features.\n\n# Create an OSM query for \"Greater London, U.K.\"\nquery = \"London, United Kingdom\"\nrestaurants = ox.features_from_place(query, tags={\"amenity\": [\"restaurant\", \"bar\", \"pub\"]})\n# Create a simple plot of the roads\nrestaurants.plot()\n# Display the plot\nplt.show()\n\n\n\n\nAnd to inspect the data queried:\n\nrestaurants.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 12197 entries, ('node', 451152) to ('relation', 17299869)\nColumns: 572 entries, addr:city to ways\ndtypes: geometry(1), object(571)\nmemory usage: 53.6+ MB\n\n\nYou do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed “restaurant in London, UK” within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?\nNote: the code cells above requires internet connectivity. For more about querying from osm see here.\nImportant: Be careful, if you query too much data, your environment is likely to get stuck."
  },
  {
    "objectID": "web-mapping.html#inspecting-spatial-data",
    "href": "web-mapping.html#inspecting-spatial-data",
    "title": "Web mapping with CARTO",
    "section": "Inspecting Spatial Data",
    "text": "Inspecting Spatial Data\n\nInspecting\nJust like a dataframe (see the OpenScience Lab), we can inspect the data (attributes table) within a spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the plot command. Let’s start by inspecting the data like we did for non spatial dataframes.\nWe can see our data is very similar to a traditional, non-spatial dataFrame, but with an additional column called geometry.\n\n# Read the first 5 rows of the data\nprint(districts.head()) \n\n  DIST_CODE             DIST_NAME  \\\n0      00AA        City of London   \n1      00AB  Barking and Dagenham   \n2      00AC                Barnet   \n3      00AD                Bexley   \n4      00AE                 Brent   \n\n                                            geometry  \n0  POLYGON ((531028.507 181611.160, 531036.062 18...  \n1  POLYGON ((550817.007 184195.999, 550814.000 18...  \n2  POLYGON ((526830.313 187535.453, 526830.302 18...  \n3  POLYGON ((552373.534 174606.900, 552372.893 17...  \n4  POLYGON ((524661.688 184631.047, 524665.261 18...  \n\n\nWe can inspect the object in different ways :\n\n# Read the first row\nprint(districts.iloc[0])\n\n# Read the first column\nprint(districts.iloc[:, 0])\n\n# Read the first row, first column\nprint(districts.iloc[0, 0])\n\n# Read the column \"DIST_NAME\"\nprint(districts['DIST_NAME'])\n\nDIST_CODE                                                 00AA\nDIST_NAME                                       City of London\ngeometry     POLYGON ((531028.5069610038 181611.159611177, ...\nName: 0, dtype: object\n0     00AA\n1     00AB\n2     00AC\n3     00AD\n4     00AE\n5     00AF\n6     00AG\n7     00AH\n8     00AJ\n9     00AK\n10    00AL\n11    00AM\n12    00AN\n13    00AP\n14    00AQ\n15    00AR\n16    00AS\n17    00AT\n18    00AU\n19    00AW\n20    00AX\n21    00AY\n22    00AZ\n23    00BA\n24    00BB\n25    00BC\n26    00BD\n27    00BE\n28    00BF\n29    00BG\n30    00BH\n31    00BJ\n32    00BK\nName: DIST_CODE, dtype: object\n00AA\n0             City of London\n1       Barking and Dagenham\n2                     Barnet\n3                     Bexley\n4                      Brent\n5                    Bromley\n6                     Camden\n7                    Croydon\n8                     Ealing\n9                    Enfield\n10                 Greenwich\n11                   Hackney\n12    Hammersmith and Fulham\n13                  Haringey\n14                    Harrow\n15                  Havering\n16                Hillingdon\n17                  Hounslow\n18                 Islington\n19    Kensington and Chelsea\n20      Kingston upon Thames\n21                   Lambeth\n22                  Lewisham\n23                    Merton\n24                    Newham\n25                 Redbridge\n26      Richmond upon Thames\n27                 Southwark\n28                    Sutton\n29             Tower Hamlets\n30            Waltham Forest\n31                Wandsworth\n32               Westminster\nName: DIST_NAME, dtype: object\n\n\nWe can read or create subsets:\n\n# dataframe can be subsetted using conditional statement\n# read the rows which have \"City of London\" as value for DIST_NAME\n# Filter rows where 'DIST_NAME' is 'City of London'\nfiltered_districts = districts[districts['DIST_NAME'] == 'City of London']\n\nprint(filtered_districts)\n\n  DIST_CODE       DIST_NAME                                           geometry\n0      00AA  City of London  POLYGON ((531028.507 181611.160, 531036.062 18...\n\n\n\n\nQuick visualisation\nLet’s start by plotting London in a colour and adding Hackney (a district) in a different colour.\n\n# Plot London in grey\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, color='lightgrey')\n\n# Add city of London (Hackney) in turquoise to the map\nhackney = districts[districts['DIST_NAME'] == 'Hackney']\nhackney.plot(ax=ax, color='turquoise')\n\nplt.show()\n\n\n\n\nSome guidance on colours in Python can be found here."
  },
  {
    "objectID": "web-mapping.html#styling-plots",
    "href": "web-mapping.html#styling-plots",
    "title": "Web mapping with CARTO",
    "section": "Styling plots",
    "text": "Styling plots\nIt is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.\nNote: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.\n\nPlotting different layers\nWe first start by plotting one layer over another\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown')  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nChanging transparency\nThe intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads in brown\n\nplt.show()\n\n\n\n\n\n\nRemoving axes\nAlthough in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n\n# Remove the axis\nax.axis('off')\n\nplt.show()\n\n\n\n\nLet us stop for a second a study each of the previous lines:\nWe have first created a figure named fig with one axis named ax by using the command plt.subplots (part of the library matplotlib, which we have imported at the top of the notebook). Note how the method is returning two elements and we can assign each of them to objects with different name (fig and ax) by simply listing them at the front of the line, separated by commas.\nSecond, we plot the geographies as before, but this time we tell the function that we want it to draw the polygons on the axis we are passing, ax. This method returns the axis with the geographies in them, so we make sure to store it on an object with the same name, ax.\nOn the third line, we effectively remove the box with coordinates.\nFinally, we draw the entire plot by calling plt.show().\n\n\nAdding a title\nAdding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n\n# Plot districts with no fill (transparent fill)\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')  # No fill, only border\n# Plot roads with transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)  # Roads with 50% transparency\n# Remove the axis\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display\nplt.show()\n\n\n\n\n\n\nChanging what border lines look like\nBorder lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:\n\n# Convert CRS from WGS 84 (EPSG:4326) to British National Grid (EPSG:27700)\npoi_gdf_bng = poi_gdf.to_crs(epsg=27700)\n\n# Plotting the geometries\nfig, ax = plt.subplots()\n# Plot districts with no fill, black borders\ndistricts.plot(ax=ax, edgecolor='black', facecolor='none')\n# Plot roads with brown color and 50% transparency\na_roads.plot(ax=ax, color='brown', alpha=0.5)\n# Plot restaurants with blue color and adjusted size\npoi_gdf_bng.plot(ax=ax, edgecolor='blue', facecolor='blue', markersize=100)# Adjust size accordingly\n# Remove the axis for a clean look\nax.axis('off')\n# Add figure title\nfig.suptitle(\"Main roads in London\")\n# Display the plot\nplt.show()\n\n\n\n\n\n\nLabelling\nLabeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.\n\niterrows() is a pandas function that iterates over DataFrame rows as (index, Series) pairs. Here, idx is the index of the row, and row is a pandas series containing the data for that particular district.\ncentroid = row['geometry'].centroid gets the centroid of each district’s geometry. row['geometry'] refers to the geometry of the district, which could be a polygon or a multipolygon. .centroid computes the geometric center (centroid) of this polygon.\nax.text() is a method from Matplotlib, used to place text at specific coordinates on the plot. centroid.x and centroid.y provide the x and y coordinates of the centroid, which determine where the text will be placed. row['DIST_NAME'] is the name of the district that will be displayed as the label. fontsize=6 sets the size of the text to 8 points. ha='center' ensures that the text is horizontally aligned to the center of the specified coordinates.\n\n\n# Plot the districts with a gray fill\nfig, ax = plt.subplots()\ndistricts.plot(ax=ax, edgecolor=\"black\", facecolor='none')\n\n# Add text labels at the centroids of the districts\nfor idx, row in districts.iterrows():\n    centroid = row['geometry'].centroid\n    ax.text(centroid.x, centroid.y, row['DIST_NAME'], fontsize=6, ha='center')\n\n# Remove axis\nax.set_axis_off()\n\nplt.show()"
  },
  {
    "objectID": "web-mapping.html#coordinate-reference-systems",
    "href": "web-mapping.html#coordinate-reference-systems",
    "title": "Web mapping with CARTO",
    "section": "Coordinate reference Systems",
    "text": "Coordinate reference Systems\n\nCRSs in Python\nCoordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.\nFirst we need to retrieve the CRS from the vector data.\n\n# Retrieve the CRS from the GeoDataFrame\ncrs = districts.crs\n# Print the CRS information\nprint(crs)\n\nEPSG:27700\n\n\nWe can also retrieve some additional information about the used CRS. For example, try to run:\n\n# Check if the CRS is geographic or not\nis_geographic = CRS(crs).is_geographic\n# Find out the CRS units\nunits_gdal = CRS(crs).axis_info[0].unit_name if CRS(crs).axis_info else None\n# Extract the SRID\nsrid = CRS(crs).to_epsg()\n# Extract the proj4string representation\nproj4string = CRS(crs).to_proj4()\n\n# Print results\nprint(f\"Is Geographic: {is_geographic}\")\nprint(f\"Units (GDAL): {units_gdal}\")\nprint(f\"SRID: {srid}\")\nprint(f\"Proj4 String: {proj4string}\")\n\nIs Geographic: False\nUnits (GDAL): metre\nSRID: 27700\nProj4 String: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +type=crs\n\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/pyproj/crs/crs.py:1293: UserWarning:\n\nYou will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n\n\n\nAs we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid EPSG:27700), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.\nIf we want to modify this and “reproject” the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS’s name “WGS84”):\nIn cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the .to_crs function can be used:\n\n# Transform the CRS to EPSG:4326\ndistricts_4326 = districts.to_crs(epsg=4326)\n\n# Optionally, print the new CRS to verify\nprint(districts_4326.crs)\n\nEPSG:4326\n\n\n\n\nFrom coordinates to spatial objects\nCRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a GeoDataFrame. For example we have some London housing transactions we want to import and use.\nWe want to transform the .csv in a GeoDataFrame using the coordinates stored in columns 17 and 18, and then we set the GeoDataFrame CRS to the British National Grid (EPSG:27700).\n\n# Import housesales data from CSV\nhousesales = pd.read_csv(\"data/London/Tables/housesales.csv\")\n\n# Filter housesales to include only those with price less than 500000\nhousesales_f = housesales[housesales['price'] &lt; 500000]\n\n# Assume columns 17 and 18 are 'longitude' and 'latitude' respectively\nhousesales_gdf = gpd.GeoDataFrame(\n    housesales_f, geometry=gpd.points_from_xy(housesales_f.greastings, housesales_f.grnorthing), crs=\"EPSG:27700\"\n)\n\nprint(housesales_gdf.head())\n\n   propid   price  lnprice  advance  age  bathroom  bedroom buyage  centheat  \\\n0       1  105000       12    85000   18         1        2     25         1   \n1       2   84000       11    79800   31         1        1     47         0   \n2       3   89000       11    84550   16         1        1     30         0   \n3       4  136000       12   106000   31         2        4     32         2   \n4       5  103550       12    88000   31         1        2     38         1   \n\n   chelec  ...  psemi  pterrace  popdens  prkdouble  prknone  prksingle  \\\n0       0  ...      0         0        3          0        0          0   \n1       0  ...      0         0        0          0        0          0   \n2       0  ...      0         1       23          0        1          0   \n3       1  ...      0         1       23          0        1          0   \n4       0  ...      0         0       39          0        0          1   \n\n   prkspace  tenfree  tenlease                       geometry  \n0         1        0         1  POINT (504998.000 188930.000)  \n1         1        0         1  POINT (505026.000 177041.000)  \n2         0        1         0  POINT (505049.000 189030.000)  \n3         0        1         0  POINT (505087.000 189238.000)  \n4         0        0         1  POINT (505132.000 183300.000)  \n\n[5 rows x 34 columns]\n\n\n\n\nZooming in or out\nIt’s important to know what CRS your data is in if you want to create zoomed versions of your maps. BBox finder is a useful tool to identify coordinates in EPSG:4326.\nHere for example we are zooming in to some of the point we created at the beginning of the lab.\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts_4326.plot(ax=ax, color='none', edgecolor='black')\n# Plot the points of interest\npoi_gdf.plot(ax=ax, color='blue', markersize=50)\n# Set the coordinate limits\nax.set_xlim(-0.180723, -0.014212)\nax.set_ylim(51.476668, 51.532337)\n# Remove axis labels and ticks\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "web-mapping.html#manipulating-spatial-tables",
    "href": "web-mapping.html#manipulating-spatial-tables",
    "title": "Web mapping with CARTO",
    "section": "Manipulating Spatial Tables",
    "text": "Manipulating Spatial Tables\nOnce we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a GeoDataFrame contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial DataFrame (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, GeoDataFrame also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.\nGeoDataFrames come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.\n\nAreaLengthCentroidsBuffers and selecting by location\n\n\nOne of the spatial aspects we often need from polygons is their area. “How big is it?” is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the GeoDataFrame you are working with is projected. If that is the case, you can calculate areas as follows:\nWe had already checked that district was projected to the British National Grid\n\ndistricts_areas = districts.area\ndistricts_areas.head()\n\nareas_in_sqkm = districts_areas / 1000000 #convert into squared kilometres\nareas_in_sqkm.head()\n\n0     3.151465\n1    37.778900\n2    86.736434\n3    64.263476\n4    43.235288\ndtype: float64\n\n\n\n\nSimilarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.\n\nstreet_length = a_roads.length\nstreet_length.head()\n\n0       7.695310\n1     374.714434\n2     417.493662\n3      45.221697\n4    1748.445461\ndtype: float64\n\n\nIf you check the dataframe you will see the lengths.\n\n\nSometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).\n\n# Create a dataframe with centroids\ncents = districts.centroid\ncents.head()\n\n0    POINT (532464.075 181219.688)\n1    POINT (548021.148 184939.599)\n2    POINT (524027.452 192316.258)\n3    POINT (548927.608 175720.862)\n4    POINT (520176.906 185829.122)\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='lightgrey', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='red', markersize=10, edgecolor='none')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()\n\n\n\n\n\n\nTo create a buffer using geopandas, simply call the buffer method, passing in the radious. For example, to draw a 1000m. buffer around every centroid of every district:\n\n# buffer\nbuf = cents.buffer(1000)\nbuf.head()\n\n0    POLYGON ((533464.075 181219.688, 533459.260 18...\n1    POLYGON ((549021.148 184939.599, 549016.333 18...\n2    POLYGON ((525027.452 192316.258, 525022.637 19...\n3    POLYGON ((549927.608 175720.862, 549922.793 17...\n4    POLYGON ((521176.906 185829.122, 521172.091 18...\ndtype: geometry\n\n\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(10, 10))\n# Plot the districts\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the centroids\ncents.plot(ax=ax, color='black', markersize=20, edgecolor='none')\n# Plot the centroid buffers\nbuf.plot(ax=ax, color='none', alpha=0.5, edgecolor='red')\n# Set minimal theme by removing axes and grid\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "web-mapping.html#joins",
    "href": "web-mapping.html#joins",
    "title": "Web mapping with CARTO",
    "section": "Joins",
    "text": "Joins"
  },
  {
    "objectID": "web-mapping.html#join-districts-with-educational-level-data",
    "href": "web-mapping.html#join-districts-with-educational-level-data",
    "title": "Web mapping with CARTO",
    "section": "Join districts with educational level data",
    "text": "Join districts with educational level data\n\n# Import qualifications data from CSV\nqualifications2001_df = pd.read_csv(\"data/London/Tables/qualifications2001_2.csv\")\n\n# Take a quick look at the table by reading the first 5 lines\nqualifications2001_df.head()\n\n\n\n\n\n\n\n\nZone_Code\nZone_Name\nPopulation1674\nNoquals\nLevel1\nLevel2\nLevel3\nLevel4\n\n\n\n\n0\n00AA\nCity of London\n6067\n607\n359\n634\n665\n3647\n\n\n1\n00AB\nBarking and Dagenham\n113579\n44873\n21654\n20564\n6626\n11615\n\n\n2\n00AC\nBarnet\n228123\n44806\n25558\n41118\n24695\n80907\n\n\n3\n00AD\nBexley\n156172\n44887\n32110\n35312\n10759\n20704\n\n\n4\n00AE\nBrent\n198712\n48915\n23913\n33280\n21121\n60432\n\n\n\n\n\n\n\nCheck the data\n\n# Join check that the code you are joining the data on is the same.\n# First check the GeoDataFrame\ndistricts.head()\n\n# Then the DataFrame\nqualifications2001_df.head()\n\n## rename(columns={'Zone-Code': 'Dist_code'}) specifies that the column name Zone-Code should be renamed to Dist_code\nqualifications2001_df.rename(columns={'Zone_Code': 'DIST_CODE'}, inplace=True)\n\nMerge the qualification dataset to the districts GeoDataFrame:\n\nMerge the qualifications2001_df DataFrame with the districts GeoDataFrame.\nThe merge is done on the DIST_CODE column, which must be present in both DataFrames.\nBy default, this performs an inner join, but you can specify different types of joins (e.g., left, right) with the ‘how’ parameter.\ngpd.GeoDataFrame(...) converts the resulting merged DataFrame into a GeoDataFrame using the ‘geopandas’ library.\ndistrict_qual is the new GeoDataFrame that contains the combined data from ‘qualifications2001_df’ and ‘districts’.\ndistricts.plot() plots the GeoDataFrame and column='level 4' specifies the column to plot.\nlegend=True adds a legend to the plot and cmap='OrRd' applies a color map.\n\n\ndistrict_qual = districts.merge(qualifications2001_df, on='DIST_CODE')\n# Prove it worked\ndistrict_qual.plot(column=\"Level4\", cmap=\"OrRd\")\n# Show the plot\nplt.show()\n\n\n\n\n\nCalculation\nNow, let’s create the share of people with level 4 qualification, i.e. create the new variable Level4p equal to the number of people with level4 qualification divided by total population:\n\n# Assuming 'Level4' and 'Pop' columns exist in the merged GeoDataFrame district_qual\ndistrict_qual['Level4p'] = district_qual['Level4'] / district_qual['Population1674']"
  },
  {
    "objectID": "web-mapping.html#saving-maps-to-figures",
    "href": "web-mapping.html#saving-maps-to-figures",
    "title": "Web mapping with CARTO",
    "section": "Saving maps to figures",
    "text": "Saving maps to figures\nCreate a file to put your maps:\n\n# Create directory \"maps\" if it doesn't exist\nos.makedirs(\"maps2\", exist_ok=True)\n\nLet’s create a simple map with the variable we just created and save to external file:\n\n# Create a figure and axes for the plot\nfig, ax = plt.subplots()\n# Plot the districts' geometry with no fill color and black edges\ndistricts.plot(ax=ax, color='none', edgecolor='black')\n# Plot the district qualifications with a color map\ndistrict_qual.plot(ax=ax, column=\"Level4\", cmap=\"OrRd\", legend=True)\n# Save the plot to a PDF file\nplt.savefig(\"maps/london_test2.pdf\")\n# Save the plot as a JPG file\nplt.savefig(\"maps/london_test2.jpg\", format='jpg', dpi=300)\n# Close the plot\nplt.close()\n\n/Users/carmen/anaconda3/envs/geo-env-new/lib/python3.10/site-packages/fontTools/misc/py23.py:11: DeprecationWarning:\n\nThe py23 module has been deprecated and will be removed in a future release. Please update your code."
  },
  {
    "objectID": "web-mapping.html#adding-baselayers",
    "href": "web-mapping.html#adding-baselayers",
    "title": "Web mapping with CARTO",
    "section": "Adding baselayers",
    "text": "Adding baselayers\nMany single datasets lack context when displayed on their own. A common approach to alleviate this is to use web tiles, which are a way of quickly obtaining geographical context to present spatial data. In Python, we can use contextily to pull down tiles and display them along with our own geographic data.\nWe can begin by creating a map in the same way we would do normally, and then use the add_basemap command to add a basemap:\n\nax = restaurants.plot(color=\"black\")\ncx.add_basemap(ax, crs=restaurants.crs, source=cx.providers.CartoDB.Voyager);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote that we need to be explicit when adding the basemap to state the coordinate reference system (crs) our data is expressed in, contextily will not be able to pick it up otherwise. Conversely, we could change our data’s CRS into Pseudo-Mercator, the native reference system for most web tiles:\n\nrestaurants_wm = restaurants.to_crs(epsg=3857)\nax = restaurants_wm.plot(color=\"black\")\ncx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik);\n\n# Show the plot\nplt.show()\n\n\n\n\nNote how the coordinates are different but, if we set it right, either approach aligns tiles and data nicely.\nNow, contextily offers a lot of options in terms of the sources and providers you can use to create your basemaps. For example, we can use satellite imagery instead. A lot more about basemap options with contextly here.\n\nf, ax = plt.subplots(1, figsize=(9, 9))\ndistricts.plot(alpha=0.5, ax=ax)\ncx.add_basemap(\n    ax, \n    crs=districts.crs,\n    source=cx.providers.Esri.WorldImagery\n)\nax.set_axis_off()\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "web-mapping.html#interactive-maps",
    "href": "web-mapping.html#interactive-maps",
    "title": "Web mapping with CARTO",
    "section": "Interactive maps",
    "text": "Interactive maps\nEverything we have seen so far relates to static maps. These are useful for publication, to include in reports or to print. However, modern web technologies afford much more flexibility to explore spatial data interactively.\nWe wil use the folium library, which is a Python wrapper for Leaflet. Here’s how you can do it:\n\n# Define the locations and popups\nlocations = {\n    \"The British Museum\": (51.5045975, -0.1459604),\n    \"Big Ben\": (51.5007325, -0.1272057),\n    \"King's Cross\": (51.5301701, -0.1319481),\n    \"The Natural History Museum\": (51.4938451, -0.173734)\n}\n\n# Create a base map\nm = folium.Map(location=[51.505, -0.127], zoom_start=14, tiles='CartoDB positron')\n\n# Add markers\nfor popup, (lat, lng) in locations.items():\n    folium.Marker(location=[lat, lng], popup=popup).add_to(m)\n\n# Display the map\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "McKinney, Wes. 2013. Python for Data Analysis: Data Wrangling with\nPandas, NumPy, and IPython. 1st ed.\nPaperback; O’Reilly Media. http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\\&path=ASIN/1449319793.\n\n\nPietrostefani, Elisabetta, and Carmen Cabrera-Arnau. 2024.\n“A Course in Geographic\nData Science.” https://pietrostefani.github.io/gds/.\n\n\nRey, Sergio J., Daniel Arribas-Bel, and Levi J. Wolf. forthcoming.\nGeographic Data Science with PySAL and the PyData Stack. CRC\npress.",
    "crumbs": [
      "Epilogue",
      "References"
    ]
  },
  {
    "objectID": "download.html",
    "href": "download.html",
    "title": "Download data folders from GitHub",
    "section": "",
    "text": "Go to https://download-directory.github.io\n\n\n\nGo to the folder you need for your Lab. For example copy: https://github.com/pietrostefani/gds/tree/main/data/London\n\n\n\nPaste it in the green box… give it a few minutes\nCheck your downloads file and unzip"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "Aims\nThe course has three primary aims:",
    "crumbs": [
      "Introduction",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#aims",
    "href": "overview.html#aims",
    "title": "Overview",
    "section": "",
    "text": "Equip students with essential skills in Geographic Data Science (GDS), improving their statistical and numerical understanding and familiarity with fundamental programming concepts and modern computational tools for GDS;\nOffer a thorough overview of key methodologies used by Geographic Data Scientists, along with insights on how and when to apply them;\nEmphasise practical applications of these techniques within real-world geographical and applied settings.",
    "crumbs": [
      "Introduction",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#learning-outcomes",
    "href": "overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, students will be able to:\n\nIllustrate advanced techniques in GIS/GDS and use them programmatically for importing, manipulating, and analysing data in various formats.\nExplain the rationale and mechanics behind key methodological approaches in GDS, both from analytical and visual perspectives.\nAssess the suitability of specific techniques, their capabilities, and how they can address relevant questions.\nImplement various spatial analysis methods and interpret the outcomes, transforming raw data into meaningful insights.\nIndependently handle new datasets using GIS/GDS tools in a programmatic manner.\nDemonstrate a sound understanding of how real-world (geo)data are produced, their potential insights and biases, as well as opportunities and limitations.",
    "crumbs": [
      "Introduction",
      "Overview"
    ]
  },
  {
    "objectID": "spatial-data.html",
    "href": "spatial-data.html",
    "title": "1  Spatial data",
    "section": "",
    "text": "1.1 Modules\nimport pandas\nimport geopandas\nimport xarray, rioxarray\nimport contextily\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "geovisualisation.html",
    "href": "geovisualisation.html",
    "title": "2  Geovisualisation",
    "section": "",
    "text": "2.1 Modules\nimport geopandas\nimport xarray, rioxarray\nimport contextily\nimport seaborn as sns\nfrom pysal.viz import mapclassify as mc\nfrom legendgram import legendgram\nimport matplotlib.pyplot as plt\nimport palettable.matplotlib as palmpl\nfrom splot.mapping import vba_choropleth",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Geovisualisation</span>"
    ]
  },
  {
    "objectID": "geovisualisation.html#data",
    "href": "geovisualisation.html#data",
    "title": "2  Geovisualisation",
    "section": "2.2 Data",
    "text": "2.2 Data\nIf you want to read more about the data sources behind this dataset, head to the Datasets section.\nAssuming you have the file locally on the path ./data/:\n\ndb = geopandas.read_file(\"./data/cambodia_regional.gpkg\")\n\nQuick visualisation:\n\nfig, ax = plt.subplots()\ndb.to_crs(\n    epsg=3857\n).plot(\n    edgecolor=\"red\",\n    facecolor=\"none\",\n    linewidth=2,\n    alpha=0.25,\n    figsize=(9, 9),\n    ax=ax\n)\ncontextily.add_basemap(\n    ax,\n    source=contextily.providers.Esri.NatGeoWorldMap\n)\nax.set_axis_off()\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndb.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 198 entries, 0 to 197\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   adm2_name   198 non-null    object  \n 1   adm2_altnm  122 non-null    object  \n 2   motor_mean  198 non-null    float64 \n 3   walk_mean   198 non-null    float64 \n 4   no2_mean    198 non-null    float64 \n 5   geometry    198 non-null    geometry\ndtypes: float64(3), geometry(1), object(2)\nmemory usage: 9.4+ KB\n\n\nWe will use the average measurement of nitrogen dioxide (no2_mean) by region throughout the block.\nTo make visualisation a bit easier below, we create an additional column with values rescaled:\n\ndb[\"no2_viz\"] = db[\"no2_mean\"] * 1e5\n\nThis way, numbers are larger and will fit more easily on legends:\n\ndb[[\"no2_mean\", \"no2_viz\"]].describe()\n\n\n\n\n\n\n\n\nno2_mean\nno2_viz\n\n\n\n\ncount\n198.000000\n198.000000\n\n\nmean\n0.000032\n3.236567\n\n\nstd\n0.000017\n1.743538\n\n\nmin\n0.000014\n1.377641\n\n\n25%\n0.000024\n2.427438\n\n\n50%\n0.000029\n2.922031\n\n\n75%\n0.000034\n3.390426\n\n\nmax\n0.000123\n12.323324",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Geovisualisation</span>"
    ]
  },
  {
    "objectID": "geovisualisation.html#choropleths",
    "href": "geovisualisation.html#choropleths",
    "title": "2  Geovisualisation",
    "section": "2.3 Choropleths",
    "text": "2.3 Choropleths\n\nfig, ax = plt.subplots()\ndb.to_crs(\n    epsg=3857\n).plot(\n    \"no2_viz\", \n    legend=True,\n    figsize=(12, 9),\n    ax=ax\n)\n\ncontextily.add_basemap(\n    ax, \n    source=contextily.providers.CartoDB.VoyagerOnlyLabels,\n    zoom=7\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n2.3.1 A classiffication problem\n\ndb[\"no2_viz\"].unique().shape\n\n(198,)\n\n\n\nsns.displot(\n    db, x=\"no2_viz\", kde=True, aspect=2\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.3.2 How to assign colors?\n\n\n\n\n\n\nImportant\n\n\n\nTo build an intuition behind each classification algorithm more easily, we create a helper method (plot_classi) that generates a visualisation of a given classification.\n\n\n\ndef plot_classi(classi, col, db):\n    \"\"\"\n    Illustrate a classiffication\n    ...\n    \n    Arguments\n    ---------\n    classi : mapclassify.classifiers\n             Classification object\n    col    : str\n             Column name used for `classi`\n    db     : geopandas.GeoDataFrame\n             Geo-table with data for\n             the classification    \n    \"\"\"\n    f, ax = plt.subplots(figsize=(12, 6))\n    ax.set_title(classi.name)\n    # KDE\n    sns.kdeplot(\n        db[col], fill=True, ax=ax\n    )\n    for i in range(0, len(classi.bins)-1):\n        ax.axvline(classi.bins[i], color=\"red\")\n    # Map\n    aux = f.add_axes([.6, .45, .32, .4])\n    db.assign(lbls=classi.yb).plot(\n        \"lbls\", cmap=\"viridis\", ax=aux\n    )\n    aux.set_axis_off()\n    plt.show()\n    return None\n\n\nEqual intervals\n\n\nclassi = mc.EqualInterval(db[\"no2_viz\"], k=7)\nclassi\n\nEqualInterval\n\n   Interval      Count\n----------------------\n[ 1.38,  2.94] |   103\n( 2.94,  4.50] |    80\n( 4.50,  6.07] |     6\n( 6.07,  7.63] |     1\n( 7.63,  9.20] |     3\n( 9.20, 10.76] |     0\n(10.76, 12.32] |     5\n\n\n\nplot_classi(classi, \"no2_viz\", db)\n\n\n\n\n\n\n\n\n\nQuantiles\n\n\nclassi = mc.Quantiles(db[\"no2_viz\"], k=7)\nclassi\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 1.38,  2.24] |    29\n( 2.24,  2.50] |    28\n( 2.50,  2.76] |    28\n( 2.76,  3.02] |    28\n( 3.02,  3.35] |    28\n( 3.35,  3.76] |    28\n( 3.76, 12.32] |    29\n\n\n\nplot_classi(classi, \"no2_viz\", db)\n\n\n\n\n\n\n\n\n\nFisher-Jenks\n\n\nclassi = mc.FisherJenks(db[\"no2_viz\"], k=7)\nclassi\n\nFisherJenks\n\n   Interval      Count\n----------------------\n[ 1.38,  2.06] |    20\n( 2.06,  2.69] |    58\n( 2.69,  3.30] |    62\n( 3.30,  4.19] |    42\n( 4.19,  5.64] |     7\n( 5.64,  9.19] |     4\n( 9.19, 12.32] |     5\n\n\n\nplot_classi(classi, \"no2_viz\", db)\n\n\n\n\n\n\n\n\n\nNow let’s dig into the internals of classi:\n\nclassi\n\nFisherJenks\n\n   Interval      Count\n----------------------\n[ 1.38,  2.06] |    20\n( 2.06,  2.69] |    58\n( 2.69,  3.30] |    62\n( 3.30,  4.19] |    42\n( 4.19,  5.64] |     7\n( 5.64,  9.19] |     4\n( 9.19, 12.32] |     5\n\n\n\nclassi.k\n\n7\n\n\n\nclassi.bins\n\narray([ 2.05617382,  2.6925931 ,  3.30281182,  4.19124954,  5.63804861,\n        9.19190206, 12.32332434])\n\n\n\nclassi.yb\n\narray([2, 3, 3, 1, 1, 2, 1, 1, 1, 0, 0, 3, 2, 1, 1, 1, 3, 1, 1, 1, 2, 0,\n       0, 4, 2, 1, 3, 1, 0, 0, 0, 1, 2, 2, 6, 5, 4, 2, 1, 3, 2, 3, 2, 1,\n       2, 3, 2, 3, 1, 1, 3, 1, 2, 3, 3, 1, 3, 3, 1, 0, 1, 1, 3, 2, 0, 0,\n       2, 1, 0, 0, 0, 2, 0, 1, 3, 3, 3, 2, 3, 2, 3, 1, 2, 3, 1, 1, 1, 1,\n       2, 1, 2, 2, 1, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 1, 2, 3, 3, 2, 0, 3,\n       1, 0, 1, 2, 1, 1, 2, 1, 2, 6, 5, 6, 2, 2, 3, 6, 3, 4, 3, 4, 2, 3,\n       0, 2, 5, 6, 4, 5, 2, 2, 2, 1, 1, 1, 2, 1, 2, 3, 3, 2, 2, 2, 3, 2,\n       1, 1, 3, 4, 2, 1, 3, 1, 2, 3, 4, 0, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2,\n       2, 2, 0, 0, 1, 2, 3, 3, 3, 3, 3, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1])\n\n\n\n\n2.3.3 How many colors?\nThe code used to generate the next figure uses more advanced features than planned for this course.\nIf you want to inspect it, look at the code cell below.\n\nvals = [3, 5, 7, 9, 12, 15]\nalgos = [\"equal_interval\", \"quantiles\", \"fisherjenks\"]\nf, axs = plt.subplots(\n    len(algos), len(vals), figsize=(3*len(vals), 3*len(algos))\n)\nfor i in range(len(algos)):\n    for j in range(len(vals)):\n        db.plot(\n            \"no2_viz\", scheme=algos[i], k=vals[j], ax=axs[i, j]\n        )\n        axs[i, j].set_axis_off()\n        if i==0:\n            axs[i, j].set_title(f\"k={vals[j]}\")\n        if j==0:\n            axs[i, j].text(\n                -0.1, \n                0.5, \n                algos[i], \n                horizontalalignment='center',\n                verticalalignment='center', \n                transform=axs[i, j].transAxes,\n                rotation=90\n            )\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.3.4 Using the right color\nFor a “safe” choice, make sure to visit ColorBrewer\n\n Categories, non-ordered\n Graduated, sequential\n Graduated, divergent\n\n\n\n2.3.5 Choropleths on Geo-Tables\n\n2.3.5.1 Streamlined\nHow can we create classifications from data on geo-tables? Two ways:\n\nDirectly within plot (only for some algorithms)\n\n\nfig, ax = plt.subplots()\ndb.plot(\n    \"no2_viz\", scheme=\"quantiles\", k=7, legend=True, ax=ax\n)\nplt.show()\n\n\n\n\n\n\n\n\nSee this tutorial for more details on fine tuning choropleths manually.\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Create an equal interval map with five bins for no2_viz .\n\n\n\n\n2.3.5.2 Manual approach\nThis is valid for any algorithm and provides much more flexibility at the cost of effort.\n\nclassi = mc.Quantiles(db[\"no2_viz\"], k=7)\n\nfig, ax = plt.subplots()\ndb.assign(\n    classes=classi.yb\n).plot(\"classes\", ax=ax)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.3.5.3 Value by alpha mapping\n\ndb['area_inv'] = 1 / db.to_crs(epsg=5726).area\n\n\nfig, ax = plt.subplots()\ndb.plot('area_inv', scheme='quantiles', ax=ax)\nax.set_title('area_inv')\nax.set_axis_off()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Set up figure and axis\nfig, ax = plt.subplots(1, figsize=(12, 9))\n# VBA choropleth\nvba_choropleth(\n    'no2_viz',          # Column for color \n    'area_inv',         # Column for transparency (alpha)\n    db,                 # Geo-table\n    rgb_mapclassify={   # Options for color classification\n        'classifier': 'quantiles', 'k':5\n    },\n    alpha_mapclassify={ # Options for alpha classification\n        'classifier': 'quantiles', 'k':5\n    },\n    legend=True,        # Add legend\n    ax=ax               # Axis\n)\n# Add boundary lines\ndb.plot(color='none', linewidth=0.05, ax=ax)\n\nplt.show()\n\n\n\n\n\n\n\n\nSee here for more examples of value-by-alpha (VBA) mapping.\n\n\n2.3.5.4 Legendgrams\nLegendgrams are a way to more closely connect the statistical characteristics of your data to the map display.\n\n\n\n\n\n\nWarning\n\n\n\nLegendgram are in an experimental development stage, so the code is a bit more involved and less stable. Use at your own risk!\n\n\nHere is an example:\n\nfig, ax = plt.subplots(figsize=(9, 9))\n\nclassi = mc.Quantiles(db[\"no2_viz\"], k=7)\n\ndb.assign(\n    classes=classi.yb\n).plot(\"classes\", ax=ax)\n\nlegendgram(\n    fig,                   # Figure object\n    ax,                  # Axis object of the map\n    db[\"no2_viz\"],       # Values for the histogram\n    classi.bins,         # Bin boundaries\n    pal=palmpl.Viridis_7,# color palette (as palettable object)\n    legend_size=(.5,.2), # legend size in fractions of the axis\n    loc = 'lower right', # matplotlib-style legend locations\n)\nax.set_axis_off()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Give Task I and II from the GDS course a go.\n\n\n\n\n\n2.3.6 Choropleths on surfaces\nAssuming you have the file locally on the path ./data/:\n\ngrid = xarray.open_rasterio(\n    \"./data/cambodia_s5_no2.tif\"\n).sel(band=1)\n\n/var/folders/79/65l52xsj7vq_4_t_l6k5bl2c0000gn/T/ipykernel_25724/3548825724.py:1: DeprecationWarning:\n\nopen_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n\n\n\n\ngrid = rioxarray.open_rasterio(\"./data/cambodia_s5_no2.tif\").sel(band=1)\n\n\nImplicit continuous equal interval\n\n\nfig, ax = plt.subplots()\n\ngrid.where(\n    grid != grid.rio.nodata\n).plot(cmap=\"viridis\", ax=ax)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ngrid.where(\n    grid != grid.rio.nodata\n).plot(cmap=\"viridis\", robust=True, ax=ax)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nDiscrete equal interval\n\n\nfig, ax = plt.subplots()\n\ngrid.where(\n    grid != grid.rio.nodata\n).plot(cmap=\"viridis\", levels=7, ax=ax)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCombining with mapclassify\n\n\ngrid_nona = grid.where(\n    grid != grid.rio.nodata\n)\n\nclassi = mc.Quantiles(\n    grid_nona.to_series().dropna(), k=7\n)\n\nfig, ax = plt.subplots()\n\ngrid_nona.plot(\n    cmap=\"viridis\", levels=classi.bins, ax=ax\n)\nplt.title(classi.name)\n\nplt.show()\n\n\n\n\n\n\n\n\n\ngrid_nona = grid.where(\n    grid != grid.rio.nodata\n)\n\nclassi = mc.FisherJenksSampled(\n    grid_nona.to_series().dropna().values, k=7\n)\n\nfig, ax = plt.subplots()\n\ngrid_nona.plot(\n    cmap=\"viridis\", levels=classi.bins, ax=ax\n)\nplt.title(classi.name)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ngrid_nona = grid.where(\n    grid != grid.rio.nodata\n)\n\nclassi = mc.StdMean(\n    grid_nona.to_series().dropna().values\n)\n\ngrid_nona.plot(\n    cmap=\"coolwarm\", levels=classi.bins, ax=ax\n)\nplt.title(classi.name)\n\nplt.show()\n\n\n\n\n\n\n\n\n\ngrid_nona = grid.where(\n    grid != grid.rio.nodata\n)\n\nclassi = mc.BoxPlot(\n    grid_nona.to_series().dropna().values\n)\n\nfig, ax = plt.subplots()\n\ngrid_nona.plot(\n    cmap=\"coolwarm\", levels=classi.bins, ax=ax\n)\nplt.title(classi.name)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Read the satellite image for Madrid used in the Chapter 1 and create three choropleths, one for each band, using the colormapsReds, Greens, Blues.\nPlay with different classification algorithms.\n\nDo the results change notably?\nIf so, why do you think that is?",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Geovisualisation</span>"
    ]
  },
  {
    "objectID": "geovisualisation.html#next-steps",
    "href": "geovisualisation.html#next-steps",
    "title": "2  Geovisualisation",
    "section": "2.4 Next steps",
    "text": "2.4 Next steps\nIf you are interested in statistical maps based on classification, here are two recommendations to check out next:\n\nOn the technical side, the documentation for mapclassify (including its tutorials) provides more detail and illustrates more classification algorithms than those reviewed in this block.\nOn a more conceptual note, Cynthia Brewer’s “Designing better maps” (Brewer 2015) is an excellent blueprint for good map making.\n\n\n\n\n\nArribas-Bel, Dani. 2019. “A Course on Geographic Data Science.” The Journal of Open Source Education 2 (14). https://doi.org/https://doi.org/10.21105/jose.00042.\n\n\nBrewer, Cynthia. 2015. Designing Better Maps: A Guide for GIS Users. ESRI press.\n\n\nPietrostefani, Elisabetta, and Carmen Cabrera-Arnau. 2024. “A Course in Geographic Data Science.” https://pietrostefani.github.io/gds/.\n\n\nRey, Sergio J., Daniel Arribas-Bel, and Levi J. Wolf. forthcoming. Geographic Data Science with PySAL and the PyData Stack. CRC press.",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Geovisualisation</span>"
    ]
  },
  {
    "objectID": "spatial-data.html#data",
    "href": "spatial-data.html#data",
    "title": "1  Spatial data",
    "section": "1.2 Data",
    "text": "1.2 Data\nIf you want to read more about the data sources behind this dataset, head to the Datasets section.\n\n1.2.1 Points\nAssuming you have the file locally on the path ./data/:\n\npts = geopandas.read_file(\"./data/madrid_abb.gpkg\")\n\n\n\n\n\n\n\nNote\n\n\n\nSometimes, points are provided as separate columns in an otherwise non-spatial table. For example imagine we have an object cols with a column named X for longitude and Y for latitude. Then, we can convert those into proper geometries by running pts = geopandas.GeoSeries( geopandas.points_from_xy(cols[\"X\"], cols[\"Y\"]).\n\n\nLet’s explore the points dataset that we loaded above.\n\npts.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 18399 entries, 0 to 18398\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype   \n---  ------           --------------  -----   \n 0   price            18399 non-null  object  \n 1   price_usd        18399 non-null  float64 \n 2   log1p_price_usd  18399 non-null  float64 \n 3   accommodates     18399 non-null  int64   \n 4   bathrooms        18399 non-null  object  \n 5   bedrooms         18399 non-null  float64 \n 6   beds             18399 non-null  float64 \n 7   neighbourhood    18399 non-null  object  \n 8   room_type        18399 non-null  object  \n 9   property_type    18399 non-null  object  \n 10  WiFi             18399 non-null  object  \n 11  Coffee           18399 non-null  object  \n 12  Gym              18399 non-null  object  \n 13  Parking          18399 non-null  object  \n 14  km_to_retiro     18399 non-null  float64 \n 15  geometry         18399 non-null  geometry\ndtypes: float64(5), geometry(1), int64(1), object(9)\nmemory usage: 2.2+ MB\n\n\n\npts.head()\n\n\n\n\n\n\n\n\nprice\nprice_usd\nlog1p_price_usd\naccommodates\nbathrooms\nbedrooms\nbeds\nneighbourhood\nroom_type\nproperty_type\nWiFi\nCoffee\nGym\nParking\nkm_to_retiro\ngeometry\n\n\n\n\n0\n$60.00\n60.0\n4.110874\n2\n1 shared bath\n1.0\n1.0\nHispanoamérica\nPrivate room\nPrivate room in apartment\n1\n0\n0\n0\n5.116664\nPOINT (-3.67688 40.45724)\n\n\n1\n$31.00\n31.0\n3.465736\n1\n1 bath\n1.0\n1.0\nCármenes\nPrivate room\nPrivate room in apartment\n1\n1\n0\n1\n5.563869\nPOINT (-3.74084 40.40341)\n\n\n2\n$60.00\n60.0\n4.110874\n6\n2 baths\n3.0\n5.0\nLegazpi\nEntire home/apt\nEntire apartment\n1\n1\n0\n1\n3.048442\nPOINT (-3.69304 40.38695)\n\n\n3\n$115.00\n115.0\n4.753590\n4\n1.5 baths\n2.0\n3.0\nJusticia\nEntire home/apt\nEntire apartment\n1\n1\n0\n1\n2.075484\nPOINT (-3.69764 40.41995)\n\n\n4\n$26.00\n26.0\n3.295837\n1\n1 private bath\n1.0\n1.0\nLegazpi\nPrivate room\nPrivate room in house\n1\n0\n0\n0\n2.648058\nPOINT (-3.69011 40.38985)\n\n\n\n\n\n\n\n\n\n1.2.2 Lines\nAssuming you have the file locally on the path ./data/:\n\nlines = geopandas.read_file(\"./data/arturo_streets.gpkg\")\n\n\nlines.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 66499 entries, 0 to 66498\nData columns (total 9 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   OGC_FID             66499 non-null  object  \n 1   dm_id               66499 non-null  object  \n 2   dist_barri          66483 non-null  object  \n 3   average_quality     66499 non-null  float64 \n 4   population_density  66499 non-null  float64 \n 5   X                   66499 non-null  float64 \n 6   Y                   66499 non-null  float64 \n 7   value               5465 non-null   float64 \n 8   geometry            66499 non-null  geometry\ndtypes: float64(5), geometry(1), object(3)\nmemory usage: 4.6+ MB\n\n\n\nlines.loc[0, \"geometry\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Print descriptive statistics for population_density and average_quality.\n\n\n\n\n1.2.3 Polygons\nAssuming you have the file locally on the path ./data/:\n\npolys = geopandas.read_file(\"./data/neighbourhoods.geojson\")\n\n\npolys.head()\n\n\n\n\n\n\n\n\nneighbourhood\nneighbourhood_group\ngeometry\n\n\n\n\n0\nPalacio\nCentro\nMULTIPOLYGON (((-3.70584 40.42030, -3.70625 40...\n\n\n1\nEmbajadores\nCentro\nMULTIPOLYGON (((-3.70384 40.41432, -3.70277 40...\n\n\n2\nCortes\nCentro\nMULTIPOLYGON (((-3.69796 40.41929, -3.69645 40...\n\n\n3\nJusticia\nCentro\nMULTIPOLYGON (((-3.69546 40.41898, -3.69645 40...\n\n\n4\nUniversidad\nCentro\nMULTIPOLYGON (((-3.70107 40.42134, -3.70155 40...\n\n\n\n\n\n\n\n\npolys.query(\"neighbourhood_group == 'Retiro'\")\n\n\n\n\n\n\n\n\nneighbourhood\nneighbourhood_group\ngeometry\n\n\n\n\n13\nPacífico\nRetiro\nMULTIPOLYGON (((-3.67015 40.40654, -3.67017 40...\n\n\n14\nAdelfas\nRetiro\nMULTIPOLYGON (((-3.67283 40.39468, -3.67343 40...\n\n\n15\nEstrella\nRetiro\nMULTIPOLYGON (((-3.66506 40.40647, -3.66512 40...\n\n\n16\nIbiza\nRetiro\nMULTIPOLYGON (((-3.66916 40.41796, -3.66927 40...\n\n\n17\nJerónimos\nRetiro\nMULTIPOLYGON (((-3.67874 40.40751, -3.67992 40...\n\n\n18\nNiño Jesús\nRetiro\nMULTIPOLYGON (((-3.66994 40.40850, -3.67012 40...\n\n\n\n\n\n\n\n\npolys.neighbourhood_group.unique()\n\narray(['Centro', 'Arganzuela', 'Retiro', 'Salamanca', 'Chamartín',\n       'Moratalaz', 'Tetuán', 'Chamberí', 'Fuencarral - El Pardo',\n       'Moncloa - Aravaca', 'Puente de Vallecas', 'Latina', 'Carabanchel',\n       'Usera', 'Ciudad Lineal', 'Hortaleza', 'Villaverde',\n       'Villa de Vallecas', 'Vicálvaro', 'San Blas - Canillejas',\n       'Barajas'], dtype=object)",
    "crumbs": [
      "Contents",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  }
]