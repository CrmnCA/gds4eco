[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geographic Data Science for Applied Economists",
    "section": "",
    "text": "Welcome\n\nThis is the website for the “Geographic Data Science for applied economists using Python”. This module is delivered by Dr. Carmen Cabrera-Arnau from the Geographic Data Science Lab at the University of Liverpool, United Kingdom. The course material has been designed by Prof. Dani Arribas-Bel, Prof. Diego Puga and Dr. Carmen Cabrera-Arnau.\n\n\n\n\n\n\n\nNote\n\n\n\nA PDF version of this course is available for download here.\n\n\n\n\nContact\n\n\n\n\nCarmen Cabrera-Arnau - c.cabrera-arnau [at] liverpool.ac.uk - Lecturer in Geographic Data Science - Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, UK.\n\n\nDani Arribas-Bel - D.Arribas-Bel [at] liverpool.ac.uk - Professor in Geographic Data Science - Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, UK.\n\n\nDiego Puga - diego.puga [at] cemfi.es - Professor - CEMFI, Casado del Alisal 5, 28014 Madrid, Spain."
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#packages-and-modules",
    "href": "quarto-notebooks/transport-costs.html#packages-and-modules",
    "title": "6  Transport costs",
    "section": "6.1 Packages and modules",
    "text": "6.1 Packages and modules\n\nimport momepy\nimport geopandas\nimport contextily\nimport xarray, rioxarray\nimport osmnx as ox\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nox.settings.overpass_settings = (\n    '[out:json][timeout:90][date:\"2021-03-07T00:00:00Z\"]'\n)"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#data",
    "href": "quarto-notebooks/transport-costs.html#data",
    "title": "6  Transport costs",
    "section": "6.2 Data",
    "text": "6.2 Data\nAssuming you have the file locally on the path ../data/:\n\nstreets = geopandas.read_file(\"../data/arturo_streets.gpkg\")\nabbs = geopandas.read_file(\"../data/madrid_abb.gpkg\")\nneis = geopandas.read_file(\"../data/neighbourhoods.geojson\")"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#pandana-graphs",
    "href": "quarto-notebooks/transport-costs.html#pandana-graphs",
    "title": "6  Transport costs",
    "section": "6.3 pandana graphs",
    "text": "6.3 pandana graphs\n\nimport pandana\n\nBefore building the routing network, we convert to graph and back in momepy to “clean” the network and ensure it complies with requirements for routing.\n\nnodes, edges = momepy.nx_to_gdf( # Convert back to geo-table\n    momepy.gdf_to_nx(            # Convert to a clean NX graph\n        streets.explode(index_parts='True')        # We \"explode\" to avoid multi-part rows\n    )\n)\nnodes = nodes.set_index(\"nodeID\") # Reindex nodes on ID\n\nOnce we have nodes and edges “clean” from the graph representation, we can build a pandana.Network object we will use for routing:\n\nstreets_pdn = pandana.Network(\n    nodes.geometry.x,\n    nodes.geometry.y,\n    edges[\"node_start\"],\n    edges[\"node_end\"],\n    edges[[\"mm_len\"]]\n)\n\nstreets_pdn\n\nGenerating contraction hierarchies with 8 threads.\nSetting CH node vector of size 49985\nSetting CH edge vector of size 66499\nRange graph removed 444 edges of 132998\n. 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n\n\n&lt;pandana.network.Network at 0x16584a850&gt;"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#shortest-path-routing",
    "href": "quarto-notebooks/transport-costs.html#shortest-path-routing",
    "title": "6  Transport costs",
    "section": "6.4 Shortest-path routing",
    "text": "6.4 Shortest-path routing\nHow do I go from A to B?\nFor example, from the first Airbnb in the geo-table…\n\nfirst = abbs.loc[[0], :].to_crs(streets.crs)\n\n…to Puerta del Sol.\n\nimport geopy\ngeopy.geocoders.options.default_user_agent = \"gds4eco\"\nsol = geopandas.tools.geocode(\n    \"Puerta del Sol, Madrid\", geopy.Nominatim\n).to_crs(streets.crs)\nsol\n\n\n\n\n\n\n\n\ngeometry\naddress\n\n\n\n\n0\nPOINT (440284.049 4474264.421)\nPuerta del Sol, Barrio de los Austrias, Sol, C...\n\n\n\n\n\n\n\nFirst we snap locations to the network:\n\npt_nodes = streets_pdn.get_node_ids(\n    [first.geometry.x.iloc[0], sol.geometry.x.iloc[0]], \n    [first.geometry.y.iloc[0], sol.geometry.y.iloc[0]]\n)\npt_nodes\n\n0     3071\n1    35729\nName: node_id, dtype: int64\n\n\nThen we can route the shortest path:\n\nroute_nodes = streets_pdn.shortest_path(\n    pt_nodes[0], pt_nodes[1]\n)\nroute_nodes\n\narray([ 3071,  3476,  8268,  8266,  8267, 18695, 18693,  1432,  1430,\n         353,  8175,  8176, 18121, 17476, 16858, 14322, 16857, 17810,\n       44795, 41220, 41217, 41221, 41652, 18924, 18928, 48943, 18931,\n       21094, 21095, 23219, 15398, 15399, 15400, 47446, 47447, 23276,\n       47448, 23259, 23260, 23261, 27951, 27952, 27953, 48327, 11950,\n       11949, 11944, 19475, 19476, 27333, 30088, 43294, 11940, 11941,\n       11942, 48325, 37484, 48316, 15893, 15890, 15891, 29954, 25453,\n        7341, 34991, 23608, 28217, 21648, 21649, 21651, 39075, 25108,\n       25102, 25101, 25100, 48518, 47287, 34623, 31187, 29615, 48556,\n       22844, 48553, 48555, 40922, 40921, 40923, 48585, 46372, 46371,\n       46370, 45675, 45676, 38778, 38777, 19144, 20498, 20497, 20499,\n       47737, 42303, 42302, 35730, 35727, 35729])\n\n\nWith this information, we can build the route line manually.\nThe code to generate the route involves writing a function and is a bit more advanced than expected for this course. If this looks too complicated, do not despair.\n\nfrom shapely.geometry import LineString\n\ndef route_nodes_to_line(nodes, network):\n    pts = network.nodes_df.loc[nodes, :]\n    s = geopandas.GeoDataFrame(\n        {\"src_node\": [nodes[0]], \"tgt_node\": [nodes[1]]},\n        geometry=[LineString(pts.values)],\n        crs=streets.crs\n    )\n    return s\n\nWe can calculate the route:\n\nroute = route_nodes_to_line(route_nodes, streets_pdn)\n\nAnd we get it back as a geo-table (with one row):\n\nroute\n\n\n\n\n\n\n\n\nsrc_node\ntgt_node\ngeometry\n\n\n\n\n0\n3071\n3476\nLINESTRING (442606.507 4478714.516, 442597.100...\n\n\n\n\n\n\n\nPlease note this builds a simplified line for the route, not one that is based on the original geometries.\n\nfig, ax = plt.subplots()\n\nroute.plot(\n    figsize=(9, 9),\n    color=\"red\",\n    ax=ax\n)\n\ncontextily.add_basemap(\n    ax, \n    crs=route.crs,\n    source=contextily.providers.CartoDB.Voyager,\n    zoom=14\n)\n\nplt.show()\n\n\n\n\nBut distance calculations are based on the original network). If we wanted to obtain the length of the route:\n\nroute_len = streets_pdn.shortest_path_length(\n    pt_nodes[0], pt_nodes[1]\n)\nround(route_len / 1000, 3) # Dist in Km\n\n5.458\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge:\n- What is the network distance between CEMFI and Puerta del Sol?\n- BONUS I: how much longer is it than if you could fly in a straight line?\n- BONUS II: if one walks at a speed of 5 Km/h, how long does the walk take you?"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#weighted-routing",
    "href": "quarto-notebooks/transport-costs.html#weighted-routing",
    "title": "6  Transport costs",
    "section": "6.5 Weighted routing",
    "text": "6.5 Weighted routing\nHow do I go from A to B passing by the “best” buildings?\nThis is really an extension of standard routing that takes advantage of the flexibility of pandana.Network objects.\nNote that the route we defined above, does not pass by the “best” buildings.\n\nbb = route.total_bounds\n\nfig, ax = plt.subplots()\n\nstreets.cx[\n    bb[0]: bb[2], bb[1]:bb[3]\n].plot(\n    \"average_quality\", scheme=\"quantiles\", ax=ax\n)\n\nroute.plot(color=\"r\", linewidth=2.5, ax=ax)\n\nax.set_title(\"Mean Building Quality\")\nax.set_axis_off()\n\nplt.show()\n\n\n\n\nThe overall process to achieve this is the very similar; the main difference is, when we build the Network object, to replace distance (mm_len) with a measure that combines distance and building quality. Note that we want to maximise building quality, but the routing algorithms use a minimisation function. Hence, our composite index will need to reflect that.\nThe strategy is divided in the following steps:\n\nRe-scale distance between 0 and 1\nBuild a measure inverse to building quality in the \\([0, 1]\\) range\nGenerate a combined measure (wdist) by picking a weighting parameter\nBuild a new Network object that incorporates wdist instead of distance\nCompute route between the two points of interest\n\nFor 1., we can use the scaler in scikit-learn:\n\nfrom sklearn.preprocessing import minmax_scale\n\nThen generate and attach to edges a scaled version of mm_len:\n\nedges[\"scaled_dist\"] = minmax_scale(edges[\"mm_len\"])\n\nWe can compare distance with scaled distance. The correlation should be perfect, the scaling is only a change of scale or unit.\n\nfig, ax = plt.subplots()\nedges.plot.scatter(\"mm_len\", \"scaled_dist\", ax=ax)\nax.set_title(\"Distance Vs Scaled Distance\")\nplt.show()\n\n\n\n\nWe move on to 2., with a similar approach. We will use the negative of the building quality average (average_quality):\n\nedges[\"scaled_inv_bquality\"] = minmax_scale(\n    -edges[\"average_quality\"]\n)\n\nAnd again, we can plot the relation between building quality and the scaled quality.\n\nfig, ax = plt.subplots()\nedges.plot.scatter(\n    \"average_quality\", \"scaled_inv_bquality\", ax=ax\n)\nax.set_title(\"Quality Vs Inv. Scaled Quality\")\nplt.show()\n\n\n\n\nTaking 1. and 2. into 3. we can build wdist. For this example, we will give each dimension the same weight (0.5), but this is at discretion of the researcher.\n\nw = 0.5\nedges[\"wdist\"] = (\n    edges[\"scaled_dist\"] * w +\n    edges[\"scaled_inv_bquality\"] * (1-w)\n)\n\nNow we can recreate the Network object based on our new measure (4.) and provide routing. Since it is the same process as with distance, we will do it all in one go:\n\n# Build new graph object\nw_graph = pandana.Network(\n    nodes.geometry.x,\n    nodes.geometry.y,\n    edges[\"node_start\"],\n    edges[\"node_end\"],\n    edges[[\"wdist\"]]\n)\n# Snap locations to their nearest node\npt_nodes = w_graph.get_node_ids(\n    [first.geometry.x.iloc[0], sol.geometry.x.iloc[0]], \n    [first.geometry.y.iloc[0], sol.geometry.y.iloc[0]]\n)\n# Generate route\nw_route_nodes = w_graph.shortest_path(\n    pt_nodes[0], pt_nodes[1]\n)\n# Build LineString\nw_route = route_nodes_to_line(\n    w_route_nodes, w_graph\n)\n\nGenerating contraction hierarchies with 8 threads.\nSetting CH node vector of size 49985\nSetting CH edge vector of size 66499\nRange graph removed 444 edges of 132998\n. 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n\n\nNow we are ready to display it on a map:\n\nfig, ax = plt.subplots()\n# Building quality\nstreets.plot(\n    \"average_quality\", \n    scheme=\"quantiles\", \n    cmap=\"magma\",\n    linewidth=0.5,\n    figsize=(9, 9), \n    ax=ax\n)\n# Shortest route\nroute.plot(\n    color=\"xkcd:orange red\", linewidth=3, ax=ax, label=\"Shortest\"\n)\n# Weighted route\nw_route.plot(\n    color=\"xkcd:easter green\", linewidth=3, ax=ax, label=\"Weighted\"\n)\n# Styling\nax.set_axis_off()\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge:\n1. Explore the differences in the output of weighted routing if you change the weight between distance and the additional constrain.\n2. Recreate weighted routing using the linearity of street segments. How can you go from A to B avoiding long streets?"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#proximity",
    "href": "quarto-notebooks/transport-costs.html#proximity",
    "title": "6  Transport costs",
    "section": "6.6 Proximity",
    "text": "6.6 Proximity\nWhat is the nearest internet cafe for Airbnb’s without WiFi?\nFirst we identify Airbnb’s without WiFi:\n\nno_wifi = abbs.query(\n    \"WiFi == '0'\"\n).to_crs(streets.crs)\n\nThen pull WiFi spots in Madrid from OpenStreetMap:\n\nicafes = ox.features_from_place(\n    \"Madrid, Spain\", tags={\"amenity\": \"internet_cafe\"}\n).to_crs(streets.crs).reset_index()\n\n\nfig, ax = plt.subplots()\n\nno_wifi.plot(\n    color=\"red\", \n    markersize=1,\n    alpha=0.5,\n    label=\"Airbnb no WiFi\",\n    figsize=(9, 9),\n    ax=ax\n)\n\nicafes.plot(\n    ax=ax, color=\"lime\", label=\"Internet cafes\"\n)\n\ncontextily.add_basemap(\n    ax, \n    crs=no_wifi.crs,\n    source=contextily.providers.CartoDB.Voyager\n)\nax.set_axis_off()\nplt.legend()\nplt.show()\n\n\n\n\nThe logic for this operation is the following:\n\nAdd the points of interest (POIs, the internet cafes) to the network object (streets_pdn)\nFind the nearest node to each POI\nFind the nearest node to each Airbnb without WiFi\nConnect each Airbnb to its nearest internet cafe\n\nWe can add the internet cafes to the network object (1.) with the set_pois method. Note we set maxitems=1 because we are only going to query for the nearest cafe. This will make computations much faster.\n\nstreets_pdn.set_pois(\n    category=\"Internet cafes\", # Our name for the layer in the `Network` object\n    maxitems=1,                # Use to count only nearest cafe\n    maxdist=100000,            # 100km so everything is included\n    x_col=icafes.geometry.x,   # X coords of cafes\n    y_col=icafes.geometry.y,   # Y coords of cafes\n)\n\nOnce the cafes are added to the network, we can find the nearest one to each node (2.). Note there are some nodes for which we can’t find a nearest cafe. These are related to disconnected parts of the network.\n\ncafe2nnode = streets_pdn.nearest_pois(\n    100000,              # Max distance to look for\n    \"Internet cafes\",    # POIs to look for\n    num_pois=1,          # No. of POIs to include\n    include_poi_ids=True # Store POI ID\n).join(# Then add the internet cafee IDs and name\n    icafes[['osmid', 'name']],\n    on=\"poi1\"\n).rename(# Rename the distance from node to cafe\n    columns={1: \"dist2icafe\"}\n)\ncafe2nnode.head()\n\n\n\n\n\n\n\n\ndist2icafe\npoi1\nosmid\nname\n\n\nnodeID\n\n\n\n\n\n\n\n\n0\n5101.421875\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n1\n5190.265137\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n2\n5252.475098\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n3\n5095.101074\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n4\n5676.117188\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n\n\n\n\n\nTo make things easier down the line, we can link cafe2nnode to the cafe IDs. And we can also link Airbnb’s to nodes (3.) following a similar approach as we have seen above:\n\nabbs_nnode = streets_pdn.get_node_ids(\n    no_wifi.geometry.x, no_wifi.geometry.y\n)\nabbs_nnode.head()\n\n26      8872\n50     10905\n62     41158\n63     34257\n221    32215\nName: node_id, dtype: int64\n\n\nFinally, we can bring together both to find out what is the nearest internet cafe for each Airbnb (4.).\n\nabb_icafe = no_wifi[\n    [\"geometry\"]     # Keep only geometries of ABBs w/o WiFi\n].assign(\n    nnode=abbs_nnode # Attach to thse ABBs the nearest node in the network\n).join(              # Join to each ABB the nearest cafe using node IDs\n    cafe2nnode, \n    on=\"nnode\"\n)\nabb_icafe.head()\n\n\n\n\n\n\n\n\ngeometry\nnnode\ndist2icafe\npoi1\nosmid\nname\n\n\n\n\n26\nPOINT (443128.256 4483599.841)\n8872\n4926.223145\n9.0\n3.770327e+09\nSilver Envíos 2\n\n\n50\nPOINT (441885.677 4475916.602)\n10905\n1876.392944\n19.0\n6.922981e+09\nLocutorio\n\n\n62\nPOINT (440439.640 4476480.771)\n41158\n1164.812988\n17.0\n5.573414e+09\nNaN\n\n\n63\nPOINT (438485.311 4471714.377)\n34257\n1466.537964\n5.0\n2.304485e+09\nNaN\n\n\n221\nPOINT (439941.104 4473117.914)\n32215\n354.268005\n15.0\n5.412145e+09\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Calculate distances to nearest internet cafe for ABBs with WiFi. On average, which of the two groups (with and without WiFi) are closer to internet cafes?"
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#accessibility",
    "href": "quarto-notebooks/transport-costs.html#accessibility",
    "title": "6  Transport costs",
    "section": "6.7 Accessibility",
    "text": "6.7 Accessibility\nThis flips the previous question on its head and, instead of asking what is the nearest POI to a given point, along the network (irrespective of distance), it asks how many POIs can I access within a network-based distance radius?\n\nparks = ox.features_from_place(\n    \"Madrid, Spain\", tags={\"leisure\": \"park\"}\n).to_crs(streets.crs)\n\n\nFor example, how many parks are within 500m(-euclidean) of an Airbnb?\n\nWe draw a radius of 500m around each AirBnb:\n\nbuffers = geopandas.GeoDataFrame(\n    geometry=abbs.to_crs(\n        streets.crs\n    ).buffer(\n        500\n    )\n)\n\nThen intersect it with the location of parks, and count by buffer (ie. Airbnb):\n\npark_count = geopandas.sjoin(\n    parks, buffers\n).groupby(\n    \"index_right\"\n).size()\n\n\nHow many parks are within 500m(-network) of an Airbnb?\n\nWe need to approach this as a calculation within the network. The logic of steps thus looks like:\n\nUse the aggregation module in pandana to count the number of parks within 500m of each node in the network\nExtract the counts for the nodes nearest to Airbnb properties\nAssign park counts to each Airbnb\n\nWe can set up the aggregate engine (1.). This involves three steps:\n\nObtain nearest node for each park\n\n\nparks_nnode = streets_pdn.get_node_ids(\n    parks.centroid.x, parks.centroid.y\n)\n\n\nInsert the parks’ nearest node through set so it can be “aggregated”\n\n\nstreets_pdn.set(\n    parks_nnode, name=\"Parks\"\n)\n\n\n“Aggregate” for a distance of 500m, effectively counting the number of parks within 500m of each node\n\n\nparks_by_node = streets_pdn.aggregate(\n    distance=500, type=\"count\", name=\"Parks\"\n)\nparks_by_node.head()\n\nnodeID\n0    5.0\n1    5.0\n2    6.0\n3    8.0\n4    1.0\ndtype: float64\n\n\nAt this point, we have the number of parks within 500m of every node in the network. To identify those that correspond to each Airbnb (3.), we first pull out the nearest nodes to each ABB:\n\nabbs_xys = abbs.to_crs(streets.crs).geometry\nabbs_nnode = streets_pdn.get_node_ids(\n    abbs_xys.x, abbs_xys.y\n)\n\nAnd use the list to assign the count of the nearest node to each Airbnb:\n\npark_count_network = abbs_nnode.map(\n    parks_by_node\n)\npark_count_network.head()\n\n0     4.0\n1     9.0\n2     5.0\n3     0.0\n4    12.0\nName: node_id, dtype: float64\n\n\n\nFor which areas do both differ most?\n\nWe can compare the two counts above to explore to what extent the street layout is constraining access to nearby parks.\n\npark_comp = geopandas.GeoDataFrame(\n    {\n        \"Euclidean\": park_count, \n        \"Network\": park_count_network\n    },\n    geometry=abbs.geometry,\n    crs=abbs.crs\n)\n\n\nfig, ax = plt.subplots()\npark_comp.plot.scatter(\"Euclidean\", \"Network\", ax=ax)\nax.axline([0, 0], [1, 1], color='red') #45-degree line\nplt.show()\n\n\n\n\nNote there are a few cases where there are more network counts than Euclidean. These are due to the slight inaccuracies introduced by calculating network distances from nodes rather than the locations themselves.\nGeographically:\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Euclidean count\nabbs.to_crs(\n    streets.crs\n).assign(\n    n_parks=park_count\n).fillna(0).plot(\n    \"n_parks\", \n    scheme=\"fisherjenkssampled\", \n    alpha=0.5,\n    markersize=1,\n    legend=True,\n    ax=axs[0]\n)\ncontextily.add_basemap(\n    axs[0], \n    crs=streets.crs,\n    source=contextily.providers.CartoDB.PositronNoLabels\n)\naxs[0].set_axis_off()\naxs[0].set_title(\"Euclidean Distances\")\n\n# Count difference\nwith_parks = park_comp.query(\n    \"(Network &gt; 0) & (Euclidean &gt; 0)\"\n)\ncount_diff = 100 * (\n    with_parks[\"Euclidean\"] - \n    with_parks[\"Network\"]\n) / with_parks[\"Euclidean\"]\nabbs.to_crs(\n    streets.crs\n).assign(\n    n_parks=count_diff\n).dropna().plot(\n    \"n_parks\", \n    scheme=\"fisherjenkssampled\", \n    alpha=0.5,\n    markersize=1,\n    legend=True,\n    ax=axs[1]\n)\ncontextily.add_basemap(\n    axs[1], \n    crs=streets.crs,\n    source=contextily.providers.CartoDB.PositronNoLabels\n)\naxs[1].set_axis_off()\naxs[1].set_title(\"Count Difference (%)\")\n\n# Network count\nabbs.to_crs(\n    streets.crs\n).assign(\n    n_parks=park_count_network\n).fillna(0).plot(\n    \"n_parks\", \n    scheme=\"fisherjenkssampled\", \n    alpha=0.5,\n    markersize=1,\n    legend=True,\n    ax=axs[2]\n)\ncontextily.add_basemap(\n    axs[2], \n    crs=streets.crs,\n    source=contextily.providers.CartoDB.PositronNoLabels\n)\naxs[2].set_axis_off()\naxs[2].set_title(\"Network Distances\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Calculate accessibility to other ABBs from each ABB through the network. How many ABBs can you access within 500m of each ABB?\nNote you will need to use the locations of ABBs both as the source and the target for routing in this case."
  },
  {
    "objectID": "quarto-notebooks/transport-costs.html#next-steps",
    "href": "quarto-notebooks/transport-costs.html#next-steps",
    "title": "6  Transport costs",
    "section": "6.8 Next steps",
    "text": "6.8 Next steps\nIf you found the content in this block useful, the following resources represent some suggestions on where to go next:\n\nThe pandana tutorial and documentation are excellent places to get a more detailed and comprehensive view into the functionality of the library"
  },
  {
    "objectID": "quarto-notebooks/datasets.html#madrid",
    "href": "quarto-notebooks/datasets.html#madrid",
    "title": "Datasets",
    "section": "Madrid",
    "text": "Madrid\n\nAirbnb properties\nThis dataset has been sourced from the course “Spatial Modelling for Data Scientists”. The file imported here corresponds to the v0.1.0 version.\nThis dataset contains a pre-processed set of properties advertised on the AirBnb website within the region of Madrid (Spain), together with house characteristics.\n\nData file madrid_abb.gpkg.\nCode used to generate the file [URL].\nFurhter information [URL].\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication.\n\n\nAirbnb neighbourhoods\nThis dataset has been directly sourced from the website Inside Airbnb. The file was imported on February 10th 2021.\nThis dataset contains neighbourhood boundaries for the city of Madrid, as provided by Inside Airbnb.\n\nData file neighbourhoods.geojson.\nFurhter information: [URL].\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication.\n\n\nArturo\nThis dataset contains the street layout of Madrid as well as scores of habitability, where available, associated with street segments. The data originate from the Arturo Project, by 300,000Km/s, and the available file here is a slimmed down version of their official street layout distributed by the project.\n\nData file download arturo_streets.gpkg.\nCode used to generate the file [Page], borrowed from here.\nFurhter information [URL]\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication.\n\n\nSentinel 2 - 120m mosaic\nThis dataset contains four scenes for the region of Madrid (Spain) extracted from the Digital Twin Sandbox Sentinel-2 collection, by the SentinelHub. Each scene corresponds to the following dates in 2019:\n\nJanuary 1st\nApril 1st\nJuly 10th\nNovember 17th\n\nEach scene includes red, green, blue and near-infrared bands.\n\nData files (Jan 1st madrid_scene_s2_120_2019-1-1.tif, Apr 1st madrid_scene_s2_120_2019-4-1.tif, Jul 10th madrid_scene_s2_120_2019-7-10.tif, Nov 27th madrid_scene_s2_120_2019-11-27.tif)\nCode used to generate the file [Page], borrowed from here\nFurhter information [URL]\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication.\n\n\nSentinel 2 - 10m GHS composite\nThis dataset contains a scene for the region of Madrid (Spain) extracted from the GHS Composite S2, by the European Commission.\n\nData file madrid_scene_s2_10_tc.tif\nCode used to generate the file [Page], borrowed from here\nFurhter information [URL]\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication."
  },
  {
    "objectID": "quarto-notebooks/datasets.html#cambodia",
    "href": "quarto-notebooks/datasets.html#cambodia",
    "title": "Datasets",
    "section": "Cambodia",
    "text": "Cambodia\n\nPollution\nSurface with \\(NO_2\\) measurements (tropospheric column) information attached from Sentinel 5.\n\nData file cambodia_s5_no2.tif\nCode used to generate the file [Page], borrowed from here\nFurhter information [URL]\n\n\n\nFriction surfaces\nThis dataset is an extraction of the following two data products by Weiss et al. (2020) {cite}weiss2020global and distributed through the Malaria Atlas Project:\n\nGlobal friction surface enumerating land-based travel walking-only speed without access to motorized transport for a nominal year 2019 (Minutes required to travel one metre)\nGlobal friction surface enumerating land-based travel speed with access to motorized transport for a nominal year 2019 (Minutes required to travel one metre)\n\nEach is provided on a separate fie.\n\n️ Data files (cambodia_2020_motorized_friction_surface.tif and cambodia_2020_walking_friction_surface.tif)\nCode used to generate the file [Page]\n️ Furhter information [URL]\n\n\n\nRegional aggregates\nThis dataset relies on boundaries from the Humanitarian Data Exchange. The file is provided by the World Food Programme through the Humanitarian Data Exchange and was accessed on February 15th 2021.`\nPollution and friction aggregated at Level 2 (municipality) administrative boundaries for Cambodia.\n\nData file cambodia_regional.gpkg\nCode used to generate the file [Page], borrowed from here\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication.\n\n\nCambodian cities\nExtract from the Urban Centre Database (UCDB), version 1.2, of the centroid for Cambodian cities.\n\n️ Data file cambodian_cities.geojson\nCode used to generate the file [Page], borrowed from here\nFurhter information [URL]\n\nThis dataset is licensed under a license CC0 1.0 Universal Public Domain Dedication."
  },
  {
    "objectID": "quarto-notebooks/references.html",
    "href": "quarto-notebooks/references.html",
    "title": "References",
    "section": "",
    "text": "Arribas-Bel, Dani. 2019. “A Course on Geographic Data\nScience.” The Journal of Open Source Education 2 (14).\nhttps://doi.org/https://doi.org/10.21105/jose.00042.\n\n\nBrewer, Cynthia. 2015. Designing Better Maps: A Guide for GIS\nUsers. ESRI press.\n\n\nMcKinney, Wes. 2013. Python for Data Analysis: Data Wrangling with\nPandas, NumPy, and IPython. 1st ed.\nPaperback; O’Reilly Media. http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\\&path=ASIN/1449319793.\n\n\nPietrostefani, Elisabetta, and Carmen Cabrera-Arnau. 2024.\n“A Course in Geographic\nData Science.” https://pietrostefani.github.io/gds/.\n\n\nRey, Sergio J., Daniel Arribas-Bel, and Levi J. Wolf. forthcoming.\nGeographic Data Science with PySAL and the PyData Stack. CRC\npress."
  },
  {
    "objectID": "quarto-notebooks/overview.html#aims",
    "href": "quarto-notebooks/overview.html#aims",
    "title": "Overview",
    "section": "Aims",
    "text": "Aims\nThe course has three primary aims:\n\nEquip students with essential skills in Geographic Data Science (GDS), improving their statistical and numerical understanding and familiarity with fundamental programming concepts and modern computational tools for GDS;\nOffer a thorough overview of key methodologies used by Geographic Data Scientists, along with insights on how and when to apply them;\nEmphasise practical applications of these techniques within real-world geographical and applied settings."
  },
  {
    "objectID": "quarto-notebooks/overview.html#learning-outcomes",
    "href": "quarto-notebooks/overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, students will be able to:\n\nIllustrate advanced techniques in GIS/GDS and use them programmatically for importing, manipulating, and analysing data in various formats.\nExplain the rationale and mechanics behind key methodological approaches in GDS, both from analytical and visual perspectives.\nAssess the suitability of specific techniques, their capabilities, and how they can address relevant questions.\nImplement various spatial analysis methods and interpret the outcomes, transforming raw data into meaningful insights.\nIndependently handle new datasets using GIS/GDS tools in a programmatic manner.\nDemonstrate a sound understanding of how real-world (geo)data are produced, their potential insights and biases, as well as opportunities and limitations."
  }
]