{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Spatial feature engineering (part II) {#sec-spatial-feature-ii}\n",
        "\n",
        "In this second part of Spatial Feature Engineering, we turn to Map Synthesis. There is only one [reading](https://geographicdata.science/book/notebooks/12_feature_engineering.html) to complete for this block, from the GDS Book\n",
        "\n",
        "## Packages and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas, geopandas\n",
        "import numpy as np\n",
        "import contextily\n",
        "import tobler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n",
        "\n",
        "If you want to read more about the data sources behind this dataset, head to the [Datasets](./data/datasets) section.\n",
        "\n",
        "Assuming you have the file locally on the path `../data/`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pts = geopandas.read_file(\"../data/madrid_abb.gpkg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be working with a modified version of `pts`:\n",
        "\n",
        "-   Since we will require distance calculations, we will switch to the Spanish official projection\n",
        "-   To make calculations in the illustration near-instantaneous, we will work with a smaller (random) sample of Airbnb properties (10% of the total)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db = pts.sample(\n",
        "    frac=0.1, random_state=123\n",
        ").to_crs(epsg=25830)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see in the description, the new CRS is expressed in metres:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db.crs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distance buffers\n",
        "\n",
        "*How many Airbnb's are within 500m of each Airbnb?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pysal.lib import weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using `DistanceBand`, we can build a spatial weights matrix that assigns `1` to each observation within 500m, and `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w500m = weights.DistanceBand.from_dataframe(\n",
        "    db, threshold=500, binary=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of neighbors can be accessed through the `cardinalities` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_neis = pandas.Series(w500m.cardinalities)\n",
        "n_neis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "db.assign(\n",
        "    n_neis=n_neis\n",
        ").plot(\"n_neis\", markersize=0.1, ax=ax)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: callout-note\n",
        "**Challenge:** Calculate the number of AirBnb properties within 250m of each other property. *What is the average?*\n",
        ":::\n",
        "\n",
        "## Distance rings\n",
        "\n",
        "*How many Airbnb's are between 500m and 1km of each Airbnb?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w1km = weights.DistanceBand.from_dataframe(\n",
        "    db, threshold=1000, binary=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we could do simply a subtraction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_ring_neis = pandas.Series(w1km.cardinalities) - n_neis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or, if we need to know *which is which*, we can use set operations on weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w_ring = weights.w_difference(w1km, w500m, constrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can confirm they're both the same:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(pandas.Series(w_ring.cardinalities) - n_ring_neis).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: callout-note\n",
        "**Challenge:** Can you create a plot with the following two lines?\n",
        "\n",
        "-   One depicting the average number of properties within a range of 50m, 100m, 250m, 500m, 750m\n",
        "-   Another one with the *increase* of average neighbors for the same distances above\n",
        ":::\n",
        "\n",
        "## Cluster membership (points)\n",
        "\n",
        "We can use the spatial configuration of observations to classify them as part of clusters or not, which can then be encoded, for example, as dummy variables in a model.\n",
        "\n",
        "We will learn a method to identify clusters of points, based on their density across space. To do this, we will use the widely used `DBSCAN` algorithm. For this method, a cluster is a concentration of at least `min_pts` points, each of them within a distance `eps` of at least one other point in the cluster. Points in the dataset are then divided into three categories:\n",
        "\n",
        "-   *Noise*, for those points outside a cluster.\n",
        "-   *Cores*, for those points inside a cluster whith at least `min_pts` points in the cluster within distance `eps`.\n",
        "-   *Borders* for points inside a cluster with less than `min_pts` other points in the cluster within distance `eps`.\n",
        "\n",
        "Both `min_pts` and eps need to be prespecified by the user before running `DBSCAN`. This is a critical, as the value of these parameters can influence significantly the final result. For more on this, check [here](https://scikit-learn.org/stable/modules/clustering.html). Before exploring this in greater depth, let us get a first run at computing `DBSCAN` in Python, with `eps` = 500 and a minimum of `min_pct` = 2% of points for a candidate cluster to be considered so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "min_pct = 2\n",
        "min_pts = len(db) * min_pct // 100\n",
        "eps = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will illustrate it with a minimum number of points of `min_pct` % of the sample and a maximum radious of `eps` metres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = DBSCAN(min_samples=min_pts, eps=eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once ready, we “fit” it to our data, but note that we first need to express the longitude and latitude of our points in metres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db['x'] = db.geometry.x\n",
        "db['y'] = db.geometry.y\n",
        "model.fit(\n",
        "    db[['x', 'y']]\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will attach the labels to `db` for easy access:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db[\"labels\"] = model.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define boundaries to turn point clusters into polygons if that fits our needs better:\n",
        "\n",
        "The code in the next cell is a bit more advanced than expected for this course, but is used here as an illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pysal.lib import cg\n",
        "\n",
        "boundaries = []\n",
        "cl_ids = [i for i in db[\"labels\"].unique() if i!=-1]\n",
        "for cl_id in cl_ids:\n",
        "    sub = db.query(f\"labels == {cl_id}\")\n",
        "    cluster_boundaries = cg.alpha_shape_auto(\n",
        "        np.array(\n",
        "            [sub.geometry.x, sub.geometry.y]\n",
        "        ).T,\n",
        "    )\n",
        "    boundaries.append(cluster_boundaries)\n",
        "boundaries = geopandas.GeoSeries(\n",
        "    boundaries, index=cl_ids, crs=db.crs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can see what the clusters look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "db.to_crs(\n",
        "    epsg=3857\n",
        ").plot(\n",
        "    markersize=0.1, color=\"lime\", ax=ax\n",
        ")\n",
        "boundaries.to_crs(\n",
        "    epsg=3857\n",
        ").plot(\n",
        "    ax=ax, edgecolor=\"red\", facecolor=\"none\"\n",
        ")\n",
        "\n",
        "contextily.add_basemap(\n",
        "    ax,\n",
        "    source=contextily.providers.CartoDB.DarkMatterNoLabels\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: callout-note\n",
        "**Challenge:** *How does the map above change if you require 5% of points instead of 2% for a candidate cluster to be considered so?*\n",
        ":::\n",
        "\n",
        "## Cluster membership (polygons)\n",
        "\n",
        "We can take a similar approach as above if we have polygon geographies instead of points. Rather than using DBSCAN, here we can rely on local indicators of spatial association (LISAs) to pick up spatial concentrations of high or low values.\n",
        "\n",
        "For the illustration, we will aggregate the location of Airbnb properties to a regular hexagonal grid, similar to how we generated it when transferring from polygons to polygons. First we create a polygon covering the extent of points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "one = geopandas.GeoSeries(\n",
        "    [cg.alpha_shape_auto(\n",
        "        np.array(\n",
        "            [db.geometry.x, db.geometry.y]\n",
        "        ).T,\n",
        "    )],\n",
        "    crs=db.crs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we can tessellate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "abb_hex = tobler.util.h3fy(\n",
        "    one, resolution=8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And obtain a count of points in each polygon:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "counts = geopandas.sjoin(\n",
        "    db, abb_hex\n",
        ").groupby(\n",
        "    \"index_right\"\n",
        ").size()\n",
        "\n",
        "abb_hex[\"count\"] = counts\n",
        "abb_hex[\"count\"] = abb_hex[\"count\"].fillna(0)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "abb_hex.plot(\"count\", scheme=\"fisherjenks\", ax=ax)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To identify spatial clusters, we rely on `esda`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pysal.explore import esda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And compute the LISA statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w = weights.Queen.from_dataframe(abb_hex)\n",
        "lisa = esda.Moran_Local(abb_hex[\"count\"], w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a visual inspection of the clusters, `splot`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pysal.viz import splot\n",
        "from splot.esda import lisa_cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lisa_cluster(lisa, abb_hex, p=0.01)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, if we want to extract the labels for each polygon, we can do so from the `lisa` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lisa.q * (lisa.p_sim < 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "If you want a bit more background into some of the techniques reviewed in this block, the following might be of interest:\n",
        "\n",
        "-   [This block](https://pietrostefani.github.io/gds/clustering.html) of the GDS Course [@courseGDS-pietrostefani-cabrera] will introduce you to more techniques like the LISAs seen above to explore the spatial dimension of the statistical properties of your data. If you want a more detailed read, [this Chapter](https://geographicdata.science/book/notebooks/04_spatial_weights.html) of the GDS Book [@reyABwolf] will do just that.\n",
        "-   [This block](https://pietrostefani.github.io/gds/points.html) of the GDS Course [@courseGDS-pietrostefani-cabrera] will introduce you to more techniques for exploring point patterns. If you want a more comprehensive read, [this Chapter](https://geographicdata.science/book/notebooks/08_point_pattern_analysis.html) of the GDS Book [@reyABwolf] will do just that."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/carmen/anaconda3/envs/geo-env-new/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}